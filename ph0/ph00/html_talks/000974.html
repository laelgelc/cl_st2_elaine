<!DOCTYPE html>
<!--[if lt IE 8]> <html class="no-js loggedout oldie ie7" lang="en"> <![endif]-->
<!--[if IE 8]> <html class="no-js loggedout oldie ie8" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--><html class='no-js loggedout' lang='en'><!--<![endif]-->
<head>
<script>
  (function (H){
  H.className=H.className.replace(/\bno-js\b/,'js');
  if (('; '+document.cookie).match(/; _ted_user_id=/)) H.className=H.className.replace(/\bloggedout\b/,'loggedin');
  })(document.documentElement)
</script><meta charset='utf-8'>
<meta property="og:image" content="https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/fb47cef7-3332-4841-8057-a7544548d607/MaxTegmark_2018-embed.jpg?c=1050%2C550&amp;w=1050" />
<meta property="og:image:secure_url" content="https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/fb47cef7-3332-4841-8057-a7544548d607/MaxTegmark_2018-embed.jpg?c=1050%2C550&amp;w=1050" />
<meta property="og:image:width" content="1050" />
<meta property="og:image:height" content="550" />
<link rel="alternate" hreflang="x-default" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript" />
<link rel="alternate" hreflang="en" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=en" />
<link rel="alternate" hreflang="es" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=es" />
<link rel="alternate" hreflang="pt-BR" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=pt-br" />
<link rel="alternate" hreflang="pt" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=pt" />
<link rel="alternate" hreflang="ko" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=ko" />
<link rel="alternate" hreflang="ru" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=ru" />
<link rel="alternate" hreflang="zh-Hans" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=zh-cn" />
<link rel="alternate" hreflang="tr" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=tr" />
<link rel="alternate" hreflang="ja" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=ja" />
<link rel="alternate" hreflang="it" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=it" />
<link rel="alternate" hreflang="nl" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=nl" />
<link rel="alternate" hreflang="th" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=th" />
<link rel="alternate" hreflang="fa" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=fa" />
<link rel="alternate" hreflang="zh-Hant" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=zh-tw" />
<link rel="alternate" hreflang="de" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=de" />
<link rel="alternate" hreflang="ar" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=ar" />
<link rel="alternate" hreflang="ku" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=ku" />
<link rel="alternate" hreflang="hu" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=hu" />
<link rel="alternate" hreflang="fr" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=fr" />
<link rel="alternate" hreflang="vi" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript?language=vi" />
<title>Max Tegmark: How to get empowered, not overpowered, by AI | TED Talk Subtitles and Transcript | TED</title>
<meta name="description" content="TED Talk Subtitles and Transcript: Many artificial intelligence researchers expect AI to outsmart humans at all tasks and jobs within decades, enabling a future where we&#39;re restricted only by the laws of physics, not the limits of our intelligence. MIT physicist and AI researcher Max Tegmark separates the real opportunities and threats from the myths, describing the concrete steps we should take today to ensure that AI ends up being the best -- rather than worst -- thing to ever happen to humanity." />
<meta name="author" content="Max Tegmark" />
<link rel="canonical" href="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript" />
<meta property="og:title" content="Transcript of &quot;How to get empowered, not overpowered, by AI&quot;" />
<meta property="og:type" content="article" />
<meta name="keywords" content="TED, Talks, Themes, Speakers, Technology, Entertainment, Design" />
<link rel="mask-icon" href="https://pa.tedcdn.com/mask-icon.svg" color="#E62B1E" sizes="any" />
<meta name="theme-color" content="#E62B1E" />
<link rel="shortcut icon" href="https://pa.tedcdn.com/favicon.ico" />
<meta name="HandheldFriendly" content="True" />
<meta name="MobileOptimized" content="320" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-title" content="TED Talks" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black" />
<link rel="apple-touch-icon" href="https://pa.tedcdn.com/apple-touch-icon.png" />
<link rel="apple-touch-icon-precomposed" href="https://pa.tedcdn.com/apple-touch-icon-precomposed.png" />
<meta name="application-name" content="TED Talks" />
<meta name="msapplication-config" content="https://www.ted.com/browserconfig.xml" />
<meta name="msapplication-TileColor" content="#000000" />
<meta http-equiv="cleartype" content="on" />
<meta name="title" content="Max Tegmark: How to get empowered, not overpowered, by AI" />
<meta property="og:description" content="TED Talk Subtitles and Transcript: Many artificial intelligence researchers expect AI to outsmart humans at all tasks and jobs within decades, enabling a future where we&#39;re restricted only by the laws of physics, not the limits of our intelligence. MIT physicist and AI researcher Max Tegmark separates the real opportunities and threats from the myths, describing the concrete steps we should take today to ensure that AI ends up being the best -- rather than worst -- thing to ever happen to humanity." />
<meta property="og:url" content="https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai/transcript" />
<meta property="fb:app_id" content="201021956610141" /><!-- (+-CONTENT-IS-LIVE-SUCCESS-+) --><link href='https://pa.tedcdn.com/javascripts/screens/22cc1a63fe14e153e41f.chunk.js' rel='prefetch'>
<link href='https://pa.tedcdn.com/javascripts/screens/af13f91547c728110d56.chunk.js' rel='prefetch'>
<link href='https://pa.tedcdn.com/javascripts/screens/global-0b2d6e2ea9b5986d5d31.chunk.css' rel='stylesheet'>
<link href='https://pa.tedcdn.com/javascripts/screens/shed-4c66e36fff66345a8ec4.chunk.css' rel='stylesheet'>
<link href='https://pa.tedcdn.com/javascripts/screens/talk-f95b2d4e916f584aa26d.chunk.css' rel='stylesheet'><script>
  if(top != self) top.location.replace(location);
</script><script>
  (function(i,r,l,d,o){
    i.__gaIn=function(){(i[r].q=i[r].q||[]).push(arguments)};
    i['GoogleAnalyticsObject']=r;i[r]=i[r]||__gaIn,i[r].l=1*new Date();
    if(l && d!="yes" && d!="1") o.userId=l[2];
    __ga('create',"UA-40781755-2",'ted.com',o);
    __ga('set',"dimension3",'logged'+(l ? 'In' : 'Out'));
  })(window,"__ga",('; '+document.cookie).match(/; (_ted_user_id|_explr_uid)=(\d+);/),(window.navigator && window.navigator.doNotTrack),{});
</script><script>
  var googletag = googletag || {};
  googletag.cmd = googletag.cmd || [];
  
  googletag.cmd.push(function() {
    googletag.pubads().enableAsyncRendering();
    googletag.enableServices();
  });
</script><script>
  _q=[];q=function(){_q.push(arguments)};
  _g=[];g=function(){_g.push(arguments)};
  
  TED = {"env":"production","assetBuster":1570738142,"playerPath":"//pb.tedcdn.com/assets/player/flash_hls/player_4_01_002.swf","assetHost":"https://pa.tedcdn.com","authHost":"https://auth.ted.com","settingsUrl":"https://www.ted.com/settings/account","signInUrl":"/session/new","signOutUrl":"https://auth.ted.com/session/logout","signInHelpUrl":"https://auth.ted.com/account/password/new","signUpUrl":"/users/new","csClientId":"7341760","gaDimensions":{"breakpoint":"dimension1","talkId":"dimension2","authState":"dimension3","playlistId":"dimension5","testId":"dimension7","embedZone":"dimension8","gaClientId":"dimension9","tedUserId":"dimension10","playContext":"dimension11","sourceContext":"dimension12","playbackRate":"dimension13","playerMode":"dimension14","proxy":"dimension15","playToken":"dimension16","subtitleLanguage":"dimension17","playerPresentation":"dimension18","videoType":"dimension19","listHasProgress":"dimension20","exploreState":"dimension21","hasEndorsement":"dimension22","exploreCTASource":"dimension23","authContext":"dimension24","streamStructure":"dimension25","streamHost":"dimension26","exploreTest":"dimension27"}};
  TED.headReady = new Date();
  TED.signOutUrl += '?referer=' + location.protocol + '//' + location.host + '/session/logout';
  
  TED.startTime = new Date();
  TED.isFirstVisit = !document.cookie.match(/; _ga=/);
  
  TED.abby = (function () {
    var abs=(document.cookie.match(/_abby_(\w+)=(\w+)/g) || []), dms=[], ts={}, t;
    for (var i=-1, l=abs.length; ++i < l;) {
      t = abs[i].match(/_abby_(\w+)=(\w+)/);
      ts[t[1]] = t[2];
      tstr = t[1] + ':' + t[2];
      if (dms.indexOf(tstr) < 0) dms.push(tstr);
    }
    if (dms.length) {
      __ga('set', "dimension7", dms.join(','));
    }
    return {tests: ts}
  }());
  
  (function() {
    var exCookie = document.cookie.match(/_exv=([^;]+)/);
  
    if (exCookie) {
      __ga('set', "dimension27", decodeURIComponent(exCookie[1]));
    }
  }());
</script>
<script>
  TED.abby.overridden = false;
  TED.abby.disabled = false;
  
  TED["controller"]="talks";TED["zone"]={"api_key":"talk_page_2","ga_category":"videoplayer","ad_unit_path":"talk","ad_targeting":{}}
</script></head>
<body class='talks-body'>
<div class='shoji' id='shoji'>
<div class='shoji__fixtures' id='shoji-fixtures'></div>
<div class='shoji__door'>
<div class='page shoji__washi'>
<noscript>
<div class='alert alert--flash alert--warning'>
<div class='container'>
<div class='h9'>You have JavaScript disabled</div>
For the best experience, please turn JavaScript on.
<a href='https://enable-javascript.com/'>Here's how</a>
</div>
</div>
</noscript>
<script>
  (function(d,h){
    if (('; '+d.cookie).match(/; _uconf=0;/)) {
      d.write(h);
      g('uconf.init',"uconf","uconf-close");
    }
  }(document,"<div class='alert alert--flash alert--warning' id='uconf'>\n<div class='container'>\n<div class='alert__container'><h4 class='h10 m5'>Your account isn't active yet.</h4>Please click on the confirmation link we sent you.\nIf you don't receive the email within ten minutes, we can\n<a href='https://auth.ted.com/account/confirmation/new'>send it again</a>.\n<a class='alert__close g g-button-modal-close' href='#' id='uconf-close'>Close</a>\n</div>\n</div>\n</div>\n"))
</script><nav class='Main-nav Main-nav--uninitialized Main-nav/Popper' id='main-nav' role='navigation'>
<div class='Main-nav/Popper__smoke Main-nav__smoke z-i:9' id='main-nav-popper-smoke'></div>
<div class='hide-lg fl:l d:n@lg' role='presentation'>
<a aria-haspopup='true' class='Main-nav__item Main-nav__label f-w:700 t-t:u undec' href='#' onclick="g('mainNav.openHamburger'); return false" role='button'><span class='if-no-svg'>Menu</span>
<svg baseProfile="tiny" xmlns="http://www.w3.org/2000/svg" width="54" height="54" viewBox="0, 0, 512, 512" class="if-svg Main-nav__icon Main-nav__icon--hamburger"><title>Main menu</title><path d="M12 80h488v56H12V80zM12 228h488v56H12v-56zM12 376h488v56H12v-56z"/></svg></a>
</div>
<a class='Main-nav__home-button ga-link' data-ga-action='home' data-ga-category='navigation.item' data-ga-label='/' href='/' rel='home'>
<svg xmlns="http://www.w3.org/2000/svg" width="96" height="54" viewBox="0, 0, 96, 54" class="Main-nav__logo"><title>TED</title><rect x="0" y="0" width="640" height="360" fill="none"/><path d="M21.244 21.053h-6.761V14.85h21.012v6.203h-6.762V39.15h-7.489V21.053zm15.414-6.203h20.43v6.203H44.147v2.992h12.941v5.837H44.147v3.065h12.941v6.203h-20.43v-24.3zm21.666 0h12.287c8.071 0 10.906 5.984 10.906 12.114 0 7.443-3.926 12.186-12.36 12.186H58.324v-24.3zm7.489 18.097h2.908c4.653 0 5.308-3.794 5.308-6.056 0-1.533-.509-5.765-5.89-5.765H65.74l.073 11.821z" fill="#E62B1E"/></svg>
<div class='Main-nav__motto c:gray f-w:200 fl:l p-x:0 show-lg' role='presentation'><div class='v-a:m w:full d:i-b l-h:n'>
<svg class='v-a:m' style='width: 210px;' viewbox='0 0 343 36' xmlns='http://www.w3.org/2000/svg'>
<path d='M0.708067,0.848485 L3.110116,0.848485 L3.110116,28.1212123 L0.708067,28.1212123 L0.708067,0.848485 Z M24.128041,0.848485 L24.128041,27.6545687 L22.097408,27.6545687 L22.097408,23.8695704 C20.691585,26.5657335 18.244411,28.1212123 14.964156,28.1212123 C9.549133,28.1212123 6.112676,24.0769675 6.112676,17.9587512 C6.112676,11.8405348 9.549133,7.79629 14.964156,7.79629 C18.140276,7.79629 20.587449,9.2999195 21.941205,11.8405348 L21.941205,0.848485 L24.128041,0.848485 Z M22.04534,17.9587512 C22.04534,12.9293699 19.389896,9.7147138 15.224494,9.7147138 C11.007024,9.7147138 8.403648,13.0330685 8.403648,18.0624497 C8.403648,23.091831 11.059092,26.2027885 15.224494,26.2027885 C19.389896,26.2027885 22.04534,23.0399817 22.04534,17.9587512 Z M45.145967,18.7844776 L29.901512,18.7844776 C30.108216,23.5293755 32.536994,26.1824368 36.567731,26.1824368 C39.719974,26.1824368 41.838695,24.3457021 42.458809,21.5395796 L44.680882,21.5395796 C43.854064,25.3661102 41.011878,28.1212123 36.516055,28.1212123 C31.090062,28.1212123 27.731114,24.1416204 27.731114,18.1212123 C27.731114,12.2028449 31.038386,8.1212123 36.464379,8.1212123 C42.148752,8.1212123 45.145967,12.5599878 45.145967,18.0701919 L45.145967,18.7844776 Z M29.901512,16.8967225 L42.768866,16.8967225 C42.562161,12.968151 40.391764,10.0089674 36.412703,10.0089674 C32.692022,10.0089674 30.31492,12.5089674 29.901512,16.8967225 Z M64.962869,8.5293755 L64.962869,27.6620286 L62.953462,27.6620286 L62.953462,24.0395796 C61.613858,26.5906 59.295313,28.1212123 56.100873,28.1212123 C50.742456,28.1212123 47.548016,24.1416204 47.548016,18.1212123 C47.548016,12.1008041 50.742456,8.1212123 56.100873,8.1212123 C59.192266,8.1212123 61.510812,9.5497837 62.850416,11.9987633 L62.850416,8.5803959 L64.962869,8.5803959 L64.962869,8.5293755 Z M62.901939,18.0701919 C62.901939,13.1212123 60.531871,9.957947 56.306965,9.957947 C52.185107,9.957947 49.711992,13.2232531 49.711992,18.1722327 C49.711992,23.1212123 52.185107,26.1824368 56.306965,26.1824368 C60.480347,26.1824368 62.901939,23.0701919 62.901939,18.0701919 Z M67.965429,21.7436613 L70.136818,21.7436613 C70.395316,24.7538653 72.101407,26.2844776 75.978886,26.2844776 C79.442768,26.2844776 81.407357,25.1110082 81.407357,22.6620286 C81.407357,20.7232531 80.166564,19.7028449 76.650983,19.0906 L74.686393,18.7334572 C70.550416,17.968151 68.585826,16.335498 68.585826,13.3252939 C68.585826,10.1110082 71.170812,8.1212123 75.513589,8.1212123 C80.735261,8.1212123 83.010049,10.468151 83.165148,14.0395796 L80.99376,14.0395796 C80.786961,11.2844776 79.184269,9.9069266 75.513589,9.9069266 C72.463305,9.9069266 70.705515,11.1314164 70.705515,13.2742735 C70.705515,15.4171306 72.308206,16.2844776 75.30679,16.8457021 L77.271379,17.2028449 C81.717556,18.0191715 83.578746,19.6008041 83.578746,22.5599878 C83.578746,26.2844776 80.476762,28.1212123 76.030586,28.1212123 C70.912314,28.1212123 68.223928,25.8252939 67.965429,21.7436613 Z M120.209988,8.7272729 L113.391269,28.1212123 L111.118363,28.1212123 L107.399061,16.6917173 C106.830835,14.9850507 106.262608,13.1232325 105.797696,11.3648486 C105.332783,13.1232325 104.764556,14.9850507 104.19633,16.6917173 L100.477029,28.1212123 L98.204123,28.1212123 L91.385404,8.7272729 L93.65831,8.7272729 L97.377611,19.3810103 C98.100809,21.5014143 98.720692,23.5701012 99.392233,25.638788 C100.012116,23.518384 100.632,21.4496971 101.30354,19.3810103 L104.7129,8.7272729 L106.985806,8.7272729 L110.446822,19.3810103 C111.118363,21.4496971 111.738246,23.5701012 112.306473,25.638788 C112.926356,23.5701012 113.597897,21.4496971 114.269437,19.3810103 L118.040395,8.7272729 L120.209988,8.7272729 Z M120.209988,18.1212123 C120.209988,12.1008041 123.875005,8.1212123 129.19186,8.1212123 C134.560336,8.1212123 138.225353,12.1008041 138.225353,18.1212123 C138.225353,24.1416204 134.560336,28.1212123 129.19186,28.1212123 C123.926625,28.1212123 120.209988,24.1416204 120.209988,18.1212123 Z M136.057314,18.1212123 C136.057314,13.1722327 133.373077,10.0089674 129.24348,10.0089674 C125.113884,10.0089674 122.481266,13.1722327 122.481266,18.1212123 C122.481266,23.0701919 125.165503,26.2334572 129.24348,26.2334572 C133.373077,26.2334572 136.057314,23.1212123 136.057314,18.1212123 Z M151.43662,8.1738438 L151.43662,10.2264754 L150.572391,10.2264754 C146.302082,10.2264754 143.912743,12.910686 143.912743,17.0685807 L143.912743,28.1212123 L141.828426,28.1212123 L141.828426,8.4370017 L143.811069,8.4370017 L143.811069,12.5422649 C144.827809,10.2264754 146.861289,8.1212123 150.369043,8.1212123 C150.674065,8.1738438 151.029924,8.1738438 151.43662,8.1738438 Z M161.645327,10.1813143 L157.610947,10.1813143 L157.610947,28.1212123 L155.434505,28.1212123 L155.434505,10.1813143 L152.037132,10.1813143 L152.037132,8.2761924 L155.434505,8.2761924 L155.434505,2.66666682 L157.610947,2.66666682 L157.610947,8.2761924 L161.645327,8.2761924 L161.645327,10.1813143 Z M179.06018,15.1166493 L179.06018,28.1212123 L176.904806,28.1212123 L176.904806,15.2745994 C176.904806,11.5890957 175.012283,9.851644 171.647797,9.851644 C168.703872,9.851644 165.654807,12.0102962 165.602237,17.0647012 L165.602237,28.1212123 L163.446863,28.1212123 L163.446863,0.848485 L165.602237,0.848485 L165.602237,11.799696 C166.811349,9.4830936 169.124433,7.9035921 172.068358,7.9035921 C176.536815,7.9035921 179.06018,10.4834446 179.06018,15.1166493 Z M189.869399,21.7436613 L192.040787,21.7436613 C192.299286,24.7538653 194.005376,26.2844776 197.882856,26.2844776 C201.346737,26.2844776 203.311327,25.1110082 203.311327,22.6620286 C203.311327,20.7232531 202.070533,19.7028449 198.554952,19.0906 L196.590363,18.7334572 C192.454385,17.968151 190.489795,16.335498 190.489795,13.3252939 C190.489795,10.1110082 193.074781,8.1212123 197.417558,8.1212123 C202.63923,8.1212123 204.914018,10.468151 205.069117,14.0395796 L202.897729,14.0395796 C202.69093,11.2844776 201.088238,9.9069266 197.417558,9.9069266 C194.367275,9.9069266 192.609484,11.1314164 192.609484,13.2742735 C192.609484,15.4171306 194.212175,16.2844776 197.210759,16.8457021 L199.175349,17.2028449 C203.621525,18.0191715 205.482715,19.6008041 205.482715,22.5599878 C205.482715,26.2844776 202.380732,28.1212123 197.934555,28.1212123 C192.816283,28.1212123 190.127897,25.8252939 189.869399,21.7436613 Z M225.299616,18.3030305 C225.299616,24.4329006 221.853199,28.4848486 216.42248,28.4848486 C213.237155,28.4848486 210.782887,26.9783551 209.425208,24.4329006 L209.425208,35.3939395 L207.284251,35.3939395 L207.284251,8.5887447 L209.320771,8.5887447 L209.320771,12.3809525 C210.730669,9.6796538 213.184936,8.1212123 216.474698,8.1212123 C221.853199,8.1212123 225.299616,12.2251084 225.299616,18.3030305 Z M223.054223,18.1991344 C223.054223,13.1601733 220.338864,10.0432902 216.161388,10.0432902 C211.931693,10.0432902 209.320771,13.2640694 209.320771,18.3030305 C209.320771,23.3419915 211.983912,26.5627707 216.161388,26.5627707 C220.391082,26.5627707 223.054223,23.2380954 223.054223,18.1991344 Z M238.510884,8.1738438 L238.510884,10.2264754 L237.646655,10.2264754 C233.376346,10.2264754 230.987007,12.910686 230.987007,17.0685807 L230.987007,28.1212123 L228.902689,28.1212123 L228.902689,8.4370017 L230.885333,8.4370017 L230.885333,12.5422649 C231.902073,10.2264754 233.935553,8.1212123 237.443307,8.1212123 C237.799166,8.1738438 238.104188,8.1738438 238.510884,8.1738438 Z M255.925737,18.7844776 L240.681281,18.7844776 C240.887985,23.5293755 243.316763,26.1824368 247.347501,26.1824368 C250.499744,26.1824368 252.618465,24.3457021 253.238578,21.5395796 L255.460652,21.5395796 C254.633834,25.3661102 251.791647,28.1212123 247.295824,28.1212123 C241.869832,28.1212123 238.510884,24.1416204 238.510884,18.1212123 C238.510884,12.2028449 241.818156,8.1212123 247.244148,8.1212123 C252.928522,8.1212123 255.925737,12.5599878 255.925737,18.0701919 L255.925737,18.7844776 Z M240.681281,16.8967225 L253.548635,16.8967225 C253.341931,12.968151 251.171534,10.0089674 247.192472,10.0089674 C243.471792,10.0089674 241.043014,12.5089674 240.681281,16.8967225 Z M275.742638,8.5293755 L275.742638,27.6620286 L273.733232,27.6620286 L273.733232,24.0395796 C272.393628,26.5906 270.075082,28.1212123 266.880642,28.1212123 C261.522226,28.1212123 258.327785,24.1416204 258.327785,18.1212123 C258.327785,12.1008041 261.522226,8.1212123 266.880642,8.1212123 C269.972036,8.1212123 272.290581,9.5497837 273.630186,11.9987633 L273.630186,8.5803959 L275.742638,8.5803959 L275.742638,8.5293755 Z M273.681709,18.0701919 C273.681709,13.1212123 271.31164,9.957947 267.086735,9.957947 C262.964876,9.957947 260.491761,13.2232531 260.491761,18.1722327 C260.491761,23.1212123 262.964876,26.1824368 267.086735,26.1824368 C271.31164,26.1824368 273.681709,23.0701919 273.681709,18.0701919 Z M296.760564,0.848485 L296.760564,27.6545687 L294.72993,27.6545687 L294.72993,23.8695704 C293.324107,26.5657335 290.876933,28.1212123 287.596679,28.1212123 C282.181656,28.1212123 278.745199,24.0769675 278.745199,17.9587512 C278.745199,11.8405348 282.181656,7.79629 287.596679,7.79629 C290.772798,7.79629 293.219972,9.2999195 294.573728,11.8405348 L294.573728,0.848485 L296.760564,0.848485 Z M294.677863,17.9587512 C294.677863,12.9293699 292.022419,9.7147138 287.857016,9.7147138 C283.691614,9.7147138 281.03617,13.0330685 281.03617,18.0624497 C281.03617,23.091831 283.691614,26.2027885 287.857016,26.2027885 C292.022419,26.2027885 294.677863,23.0399817 294.677863,17.9587512 Z M300.363637,3.69268457 C300.363637,2.79767386 301.177234,2.06060621 302.165173,2.06060621 C303.153113,2.06060621 303.96671,2.79767386 303.96671,3.69268457 C303.96671,4.58769528 303.153113,5.3247629 302.165173,5.3247629 C301.235348,5.3247629 300.363637,4.58769528 300.363637,3.69268457 Z M301.002892,8.3783289 L303.385569,8.3783289 L303.385569,28.1212123 L301.002892,28.1212123 L301.002892,8.3783289 Z M323.183099,15.2235455 L323.183099,28.1212123 L321.027725,28.1212123 L321.027725,15.3801973 C321.027725,11.7249881 319.135202,10.001818 315.770717,10.001818 C312.826792,10.001818 309.777726,12.1427263 309.725156,17.1555846 L309.725156,28.1212123 L307.569783,28.1212123 L307.569783,8.5397343 L309.620016,8.5397343 L309.620016,12.1949435 C310.829128,9.7407316 313.194782,8.1219961 316.191277,8.1219961 C320.659735,8.0697788 323.183099,10.6284253 323.183099,15.2235455 Z M343,8.5380913 L343,27.3497594 C343,32.7170775 340.336552,36.0000002 334.497455,36.0000002 C329.73398,36.0000002 327.172972,33.4987257 326.814431,29.9031437 L328.914458,29.9031437 C329.272999,32.6128577 331.168145,34.1761542 334.548675,34.1761542 C338.851168,34.1761542 340.951194,31.9875391 340.951194,27.3497594 L340.951194,24.6921553 C339.51703,27.08921 337.212123,28.5482868 334.138914,28.5482868 C328.863238,28.5482868 325.585148,24.4837158 325.585148,18.3347495 C325.585148,12.1857832 328.863238,8.1212123 334.138914,8.1212123 C337.263343,8.1212123 339.67069,9.6323989 341.053635,12.1857832 L341.053635,8.5380913 L343,8.5380913 Z M340.951194,18.3347495 C340.951194,13.2800908 338.390186,10.049278 334.343794,10.049278 C330.194962,10.049278 327.736394,13.3843105 327.736394,18.3347495 C327.736394,23.2851885 330.246182,26.6202211 334.343794,26.6202211 C338.390186,26.6202211 340.951194,23.4415181 340.951194,18.3347495 Z' fill='currentColor'></path>
</svg>
</div></div>
</a>
<div class='pos:a right:0 top:0 Main-nav__bar' role='presentation'>
<ul class='sl fl:l show-lg' role='menubar'>
<li class='pos:r fl:l z-i:10 Main-nav__category' data-popper-name='watch' data-popper-root role='presentation'>
<a aria-haspopup class='Main-nav__category__label Main-nav__item Main-nav__label f-w:700 t-t:u undec' data-popper-target href='#' onclick='return false' role='menuitem'>Watch</a>
<ul aria-hidden class='Main-nav/Popper__popup Main-nav__category__list popup popup--inverse popup--tailed popup--tailed--center popup--tailed--top sl' role='menu'>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='watch' data-ga-category='navigation.item' data-ga-label='/talks' href='/talks'>
<div class='f-w:700 m-b:.1'>TED Talks</div>
<div class='c:gray'>Browse the library of TED talks and speakers</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='watch' data-ga-category='navigation.item' data-ga-label='/recommends?exploreCTASource=main-nav.item' href='/recommends?exploreCTASource=main-nav.item'>
<div class='f-w:700 m-b:.1'>TED Recommends</div>
<div class='c:gray'>Get TED Talks picked just for you</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='watch' data-ga-category='navigation.item' data-ga-label='/playlists' href='/playlists'>
<div class='f-w:700 m-b:.1'>Playlists</div>
<div class='c:gray'>100+ collections of TED Talks, for curious minds</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='watch' data-ga-category='navigation.item' data-ga-label='/series' href='/series'>
<div class='f-w:700 m-b:.1'>TED Series</div>
<div class='c:gray'>Go deeper into fascinating topics with original video series from TED.</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='watch' data-ga-category='navigation.item' data-ga-label='/watch/ted-ed' href='/watch/ted-ed'>
<div class='f-w:700 m-b:.1'>TED-Ed videos</div>
<div class='c:gray'>Watch, share and create lessons with TED-Ed</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='watch' data-ga-category='navigation.item' data-ga-label='/watch/tedx-talks' href='/watch/tedx-talks'>
<div class='f-w:700 m-b:.1'>TEDx Talks</div>
<div class='c:gray'>Talks from independently organized local events</div>
</a>
</li>
</ul>
</li>
<li class='pos:r fl:l z-i:10 Main-nav__category' data-popper-name='discover' data-popper-root role='presentation'>
<a aria-haspopup class='Main-nav__category__label Main-nav__item Main-nav__label f-w:700 t-t:u undec' data-popper-target href='#' onclick='return false' role='menuitem'>Discover</a>
<ul aria-hidden class='Main-nav/Popper__popup Main-nav__category__list popup popup--inverse popup--tailed popup--tailed--center popup--tailed--top sl' role='menu'>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='discover' data-ga-category='navigation.item' data-ga-label='/topics' href='/topics'>
<div class='f-w:700 m-b:.1'>Topics</div>
<div class='c:gray'>Explore TED offerings by topic</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='discover' data-ga-category='navigation.item' data-ga-label='/podcasts' href='/podcasts'>
<div class='f-w:700 m-b:.1'>Podcasts</div>
<div class='c:gray'>TED's original podcast initiatives</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='discover' data-ga-category='navigation.item' data-ga-label='/read/ted-books' href='/read/ted-books'>
<div class='f-w:700 m-b:.1'>TED Books</div>
<div class='c:gray'>Short books to feed your craving for ideas</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='discover' data-ga-category='navigation.item' data-ga-label='http://ideas.ted.com' href='http://ideas.ted.com'>
<div class='f-w:700 m-b:.1'>Ideas Blog</div>
<div class='c:gray'>Our daily coverage of the world of ideas</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='discover' data-ga-category='navigation.item' data-ga-label='/newsletter' href='/newsletter'>
<div class='f-w:700 m-b:.1'>Newsletter</div>
<div class='c:gray'>Inspiration delivered straight to your inbox</div>
</a>
</li>
</ul>
</li>
<li class='pos:r fl:l z-i:10 Main-nav__category' data-popper-name='attend' data-popper-root role='presentation'>
<a aria-haspopup class='Main-nav__category__label Main-nav__item Main-nav__label f-w:700 t-t:u undec' data-popper-target href='#' onclick='return false' role='menuitem'>Attend</a>
<ul aria-hidden class='Main-nav/Popper__popup Main-nav__category__list popup popup--inverse popup--tailed popup--tailed--center popup--tailed--top sl' role='menu'>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='attend' data-ga-category='navigation.item' data-ga-label='/attend/conferences' href='/attend/conferences'>
<div class='f-w:700 m-b:.1'>Conferences</div>
<div class='c:gray'>Take part in our events: TED, TEDGlobal and more</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='attend' data-ga-category='navigation.item' data-ga-label='/tedx/events' href='/tedx/events'>
<div class='f-w:700 m-b:.1'>TEDx events</div>
<div class='c:gray'>Find and attend local, independently organized events</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='attend' data-ga-category='navigation.item' data-ga-label='/attend/ted-on-screen' href='/attend/ted-on-screen'>
<div class='f-w:700 m-b:.1'>TED on screen</div>
<div class='c:gray'>Experience TED from home or in theaters</div>
</a>
</li>
</ul>
</li>
<li class='pos:r fl:l z-i:10 Main-nav__category' data-popper-name='participate' data-popper-root role='presentation'>
<a aria-haspopup class='Main-nav__category__label Main-nav__item Main-nav__label f-w:700 t-t:u undec' data-popper-target href='#' onclick='return false' role='menuitem'>Participate</a>
<ul aria-hidden class='Main-nav/Popper__popup Main-nav__category__list popup popup--inverse popup--tailed popup--tailed--center popup--tailed--top sl' role='menu'>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='participate' data-ga-category='navigation.item' data-ga-label='/participate/nominate' href='/participate/nominate'>
<div class='f-w:700 m-b:.1'>Nominate</div>
<div class='c:gray'>Recommend speakers, TED Prize recipients, Fellows and more</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='participate' data-ga-category='navigation.item' data-ga-label='/participate/organize-a-local-tedx-event' href='/participate/organize-a-local-tedx-event'>
<div class='f-w:700 m-b:.1'>Organize a local TEDx event</div>
<div class='c:gray'>Rules and resources to help you plan a local TEDx event</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='participate' data-ga-category='navigation.item' data-ga-label='/participate/translate' href='/participate/translate'>
<div class='f-w:700 m-b:.1'>Translate</div>
<div class='c:gray'>Bring TED to the non-English speaking world</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='participate' data-ga-category='navigation.item' data-ga-label='/participate/ted-fellows-program' href='/participate/ted-fellows-program'>
<div class='f-w:700 m-b:.1'>TED Fellows</div>
<div class='c:gray'>Join or support innovators from around the globe</div>
</a>
</li>
</ul>
</li>
<li class='pos:r fl:l z-i:10 Main-nav__category' data-popper-name='about' data-popper-root role='presentation'>
<a aria-haspopup class='Main-nav__category__label Main-nav__item Main-nav__label f-w:700 t-t:u undec' data-popper-target href='#' onclick='return false' role='menuitem'>About</a>
<ul aria-hidden class='Main-nav/Popper__popup Main-nav__category__list popup popup--inverse popup--tailed popup--tailed--center popup--tailed--top sl' role='menu'>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='about' data-ga-category='navigation.item' data-ga-label='/about/our-organization' href='/about/our-organization'>
<div class='f-w:700 m-b:.1'>Our organization</div>
<div class='c:gray'>Our mission, history, team, and more</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='about' data-ga-category='navigation.item' data-ga-label='/about/conferences' href='/about/conferences'>
<div class='f-w:700 m-b:.1'>Conferences</div>
<div class='c:gray'>TED Conferences, past, present, and future</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='about' data-ga-category='navigation.item' data-ga-label='/about/programs-initiatives' href='/about/programs-initiatives'>
<div class='f-w:700 m-b:.1'>Programs &amp; Initiatives</div>
<div class='c:gray'>Details about TED's world-changing initiatives</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='about' data-ga-category='navigation.item' data-ga-label='/about/partner-with-ted' href='/about/partner-with-ted'>
<div class='f-w:700 m-b:.1'>Partner with TED</div>
<div class='c:gray'>Learn how you can partner with us</div>
</a>
</li>
<li role='menuitem'>
<a class='d:b hover/bg:gray-ll Main-nav__fs-1 p-x:4 p-y:.8 undec ga-link' data-ga-action='about' data-ga-category='navigation.item' data-ga-label='http://blog.ted.com' href='http://blog.ted.com'>
<div class='f-w:700 m-b:.1'>TED Blog</div>
<div class='c:gray'>Updates from TED and highlights from our global community</div>
</a>
</li>
</ul>
</li>
</ul>
<div class='Main-nav__divider nav__divider fl:l show-lg'></div>
<div class='loggedin-only fl:l pos:r z-i:10' data-popper-name='account' data-popper-root><a class='Main-nav__item Main-nav__account-button' data-popper-target href='/dashboard' id='main-nav-account-button' onclick='return false' role='button' title='Your account'>
<div class='Main-nav__account-button__avatar'>
<div class='Main-nav__account-button__badge'></div>
</div>
</a>
<div aria-hidden class='Main-nav/Popper__popup Main-nav__category__list Main-nav__category__list--account popup popup--inverse popup--tailed popup--tailed--center popup--tailed--top' id='main-nav-account-menu' role='menu'></div></div>
<a class='Main-nav__item Main-nav__label auth-login f-w:700 fl:l loggedout-only t-t:u undec' href='/session/new'>Log in</a>
<div class='Main-nav__divider fl:l show-lg'></div>
<div class='fl:l show-lg'>
<a class='Main-nav__item' href='/search' id='main-nav-search' role='button'>
<svg baseProfile="tiny" xmlns="http://www.w3.org/2000/svg" width="54" height="54" viewBox="0 0 512 512" class="Main-nav__icon Main-nav__icon--search"><title>Search</title><path d="M221.414 12.31C105.96 12.31 12 106.164 12 221.475c0 115.34 93.96 209.202 209.452 209.202 41.684 0 80.52-12.4 113.205-33.512l89.652 89.576c17.304 17.267 45.413 17.267 62.697 0 17.342-17.322 17.304-45.374 0-62.677l-89.634-89.5c21.13-32.646 33.512-71.406 33.512-113.09-.02-115.31-93.92-209.163-209.47-209.163zm167.5 209.165c0 92.267-75.136 167.27-167.462 167.27-92.344 0-167.462-75.04-167.462-167.27 0-92.22 75.118-167.25 167.462-167.193 92.326 0 167.424 74.973 167.463 167.193z"/></svg>
</a>
</div>
</div>
<form action='/search' aria-hidden='true' class='Main-nav__search pos:a right:0' id='main-nav-search-form' role='search'>
<div class='Main-nav__search__content left:0 pos:a'>
<div class='Main-nav__divider fl:l'></div>
<label>
<span class='screen-reader-text'>
Search:
</span>
<input aria-label='Search' autocorrect='off' class='Main-nav__fs-6 Main-nav__search__input' name='q' placeholder='Type to search' tabindex='-1' title='Press Enter to begin search'>
</label>
<a aria-label='Close' class='Main-nav__search__close fl:r' href='#' role='button' tabindex='-1'>
<svg xmlns="http://www.w3.org/2000/svg" width="54" height="54" viewBox="0, 0, 30, 30" class="Main-nav__icon"><title>Cancel search</title><path d="M24.5 6.718L6.936 24.282 24.5 6.718zm-18 0l17.564 17.564L6.5 6.718z" stroke="#414141" stroke-width="2" stroke-linecap="square" fill="none"/></svg>
</a>
</div>
</form>
</nav>
<div id='main-nav-slideouts'></div>
<script>g("mainNav.init",{"menuItems":[{"label":"Watch","name":"watch","items":[{"url":"/talks","label":"TED Talks","info":"Browse the library of TED talks and speakers"},{"url":"/recommends?exploreCTASource=main-nav.item","label":"TED Recommends","info":"Get TED Talks picked just for you"},{"url":"/playlists","label":"Playlists","info":"100+ collections of TED Talks, for curious minds"},{"url":"/series","label":"TED Series","info":"Go deeper into fascinating topics with original video series from TED."},{"url":"/watch/ted-ed","label":"TED-Ed videos","info":"Watch, share and create lessons with TED-Ed"},{"url":"/watch/tedx-talks","label":"TEDx Talks","info":"Talks from independently organized local events"}]},{"label":"Discover","name":"discover","items":[{"url":"/topics","label":"Topics","info":"Explore TED offerings by topic"},{"url":"/podcasts","label":"Podcasts","info":"TED's original podcast initiatives"},{"url":"/read/ted-books","drilldown":true,"label":"TED Books","info":"Short books to feed your craving for ideas"},{"url":"http://ideas.ted.com","label":"Ideas Blog","info":"Our daily coverage of the world of ideas","external":true},{"url":"/newsletter","label":"Newsletter","info":"Inspiration delivered straight to your inbox"}]},{"label":"Attend","name":"attend","items":[{"url":"/attend/conferences","drilldown":true,"label":"Conferences","info":"Take part in our events: TED, TEDGlobal and more"},{"url":"/tedx/events","label":"TEDx events","info":"Find and attend local, independently organized events"},{"url":"/attend/ted-on-screen","label":"TED on screen","info":"Experience TED from home or in theaters"}]},{"label":"Participate","name":"participate","items":[{"url":"/participate/nominate","label":"Nominate","info":"Recommend speakers, TED Prize recipients, Fellows and more"},{"url":"/participate/organize-a-local-tedx-event","drilldown":true,"label":"Organize a local TEDx event","info":"Rules and resources to help you plan a local TEDx event"},{"url":"/participate/translate","drilldown":true,"label":"Translate","info":"Bring TED to the non-English speaking world"},{"url":"/participate/ted-fellows-program","label":"TED Fellows","info":"Join or support innovators from around the globe"}]},{"label":"About","name":"about","items":[{"url":"/about/our-organization","drilldown":true,"label":"Our organization","info":"Our mission, history, team, and more"},{"url":"/about/conferences","drilldown":true,"label":"Conferences","info":"TED Conferences, past, present, and future"},{"url":"/about/programs-initiatives","label":"Programs & Initiatives","info":"Details about TED's world-changing initiatives"},{"url":"/about/partner-with-ted","label":"Partner with TED","info":"Learn how you can partner with us"},{"url":"http://blog.ted.com","label":"TED Blog","info":"Updates from TED and highlights from our global community","external":true}]}]})</script><div class='main talks-main' role='main'>
<script>
		__ga('set', 'dimension2', 17851);
	</script>

	<div
		itemscope
		itemtype="http://schema.org/VideoObject"
	>
		<link href='https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai' itemprop='url'>
<meta content='How to get empowered, not overpowered, by AI' itemprop='name'>
<meta content="Many artificial intelligence researchers expect AI to outsmart humans at all tasks and jobs within decades, enabling a future where we're restricted only by the laws of physics, not the limits of our intelligence. MIT physicist and AI researcher Max Tegmark separates the real opportunities and threats from the myths, describing the concrete steps we should take today to ensure that AI ends up being the best — rather than worst — thing to ever happen to humanity." itemprop='description'>
<meta content='PT17M15S' itemprop='duration'>
<meta content='2018-06-13T14:55:18+00:00' itemprop='uploadDate'>
<meta content='1385199' itemprop='interactionCount'>
<link content='https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/fb47cef7-3332-4841-8057-a7544548d607/MaxTegmark_2018-embed.jpg?quality=95&amp;w=480' itemprop='thumbnailUrl'>
<span itemprop='author' itemscope itemtype='http://schema.org/Person'>
<link href='/speakers/max_tegmark' itemprop='url'>
<meta content='Max Tegmark' itemprop='name'>
<link href='https://pe.tedcdn.com/images/ted/30749111506edf399fa849e6787e757365800ad3_254x191.jpg' itemprop='image'>
</span>
<link href='https://embed.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai' itemprop='embedURL'>
<meta content='Flash HTML5' itemprop='playerType'>
<meta content='640' itemprop='width'>
<meta content='360' itemprop='height'>
<link href='https://creativecommons.org/licenses/by-nc-nd/4.0/' itemprop='license'>


		<div data-talk-page>
			<div class="bg:gray-ll">
	<div class="m-x:a pos:r p-t:5@xxl" style="max-width:106.25rem">
		<div class="Grid">

			<!-- Main column -->
			<div class="Grid__cell bg:white w:2of3@md">

				<!-- Video placeholder -->
				<div
	class="
		bg:black
		w:full
		pos:r
	"
	style="
		padding-bottom:56.25%;
		background-image: url(https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/fb47cef7-3332-4841-8057-a7544548d607/MaxTegmark_2018-embed.jpg?q=50&amp;w=15);
		background-size: cover;
		background-repeat: no-repeat;
	"
	>
	<div
		class="pos:a Spinner"
		style="
			top:50%;
			left:50%;
			margin-top:-50px;
			margin-left:-50px;
			width:100px;
			height:100px;
		"></div>
	<!-- Talk meta -->
	<div
		class="
			pos:a
			bottom:6
		"
	>
		<div class="p:1 p-x:4 t-a:l">
			<div
				class="
					d:n
					f:.8
					f:1@md
					m-b:.5
					t-t:u
					c:white
				"
			>
				Max Tegmark
			</div>
			<div
				class="
					d:n
					f-w:700
					f:.9
					f:1@xxl
					c:white
				"
			>
				<span>
					1,385,199
					<span className="f-w:400"> views</span>
				</span>
				<span> • 17:15</span>
			</div>
		</div>
	</div>
</div>


				<!-- Tab placeholder -->
				<div class="c:black d:f o-x:s o-y:h p-t:.5 p-x:2 sl b-b:1 b-c:gray-l c:gray p-l:0@lg">
					<div class="pos:r t-d:n c:current t-a:l m-l:2 m-r:1 d:b hover/b-b:red hover/b-b-s:3" style="white-space: nowrap; top: 1px;">
						<div class="p-t:.5 cur:p p-b:.4 d:b f-w:700" style="visibility:hidden">
							<span class="c:black">Details</span>
							<span class=" d:b f-w:400 f:.9 ">About the talk</span>
						</div>
					</div>
				</div>

				<!-- Text container -->
				<div class="p:2 p-t:4@md">
					<div class="m-b:7 p-l:.5">

						<!-- Language selection placeholder -->
						<div class="a-i:c d:f@md m-b:2 m-b:5@md m-t:.5">
							<div class="pos:r w:1of3@md w:2of5@md">
								<select class="Form-input b b-c:gray-l b-r:.1 bg:white c:black p:1 w:full" style="visibility: hidden"></select>
							</div>
						</div><!-- /Language selection placeholder -->

						<!-- Transcript text -->
							<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											After 13.8 billion years
of cosmic history,
											our universe has woken up
											and become aware of itself.
											From a small blue planet,
											tiny, conscious parts of our universe
have begun gazing out into the cosmos
											with telescopes,
											discovering something humbling.
											We&#39;ve discovered that our universe
is vastly grander
											than our ancestors imagined
											and that life seems to be an almost
imperceptibly small perturbation
											on an otherwise dead universe.
											But we&#39;ve also discovered
something inspiring,
											which is that the technology
we&#39;re developing has the potential
											to help life flourish like never before,
											not just for centuries
but for billions of years,
											and not just on earth but throughout
much of this amazing cosmos.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											I think of the earliest life as &quot;Life 1.0&quot;
											because it was really dumb,
											like bacteria, unable to learn
anything during its lifetime.
											I think of us humans as &quot;Life 2.0&quot;
because we can learn,
											which we in nerdy, geek speak,
											might think of as installing
new software into our brains,
											like languages and job skills.
											&quot;Life 3.0,&quot; which can design not only
its software but also its hardware
											of course doesn&#39;t exist yet.
											But perhaps our technology
has already made us &quot;Life 2.1,&quot;
											with our artificial knees,
pacemakers and cochlear implants.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											So let&#39;s take a closer look
at our relationship with technology, OK?
											As an example,
											the Apollo 11 moon mission
was both successful and inspiring,
											showing that when we humans
use technology wisely,
											we can accomplish things
that our ancestors could only dream of.
											But there&#39;s an even more inspiring journey
											propelled by something
more powerful than rocket engines,
											where the passengers
aren&#39;t just three astronauts
											but all of humanity.
											Let&#39;s talk about our collective
journey into the future
											with artificial intelligence.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											My friend Jaan Tallinn likes to point out
that just as with rocketry,
											it&#39;s not enough to make
our technology powerful.
											We also have to figure out,
if we&#39;re going to be really ambitious,
											how to steer it
											and where we want to go with it.
											So let&#39;s talk about all three
for artificial intelligence:
											the power, the steering
and the destination.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											Let&#39;s start with the power.
											I define intelligence very inclusively —
											simply as our ability
to accomplish complex goals,
											because I want to include both
biological and artificial intelligence.
											And I want to avoid
the silly carbon-chauvinism idea
											that you can only be smart
if you&#39;re made of meat.
											It&#39;s really amazing how the power
of AI has grown recently.
											Just think about it.
											Not long ago, robots couldn&#39;t walk.
											Now, they can do backflips.
											Not long ago,
											we didn&#39;t have self-driving cars.
											Now, we have self-flying rockets.
											Not long ago,
											AI couldn&#39;t do face recognition.
											Now, AI can generate fake faces
											and simulate your face
saying stuff that you never said.
											Not long ago,
											AI couldn&#39;t beat us at the game of Go.
											Then, Google DeepMind&#39;s AlphaZero AI
took 3,000 years of human Go games
											and Go wisdom,
											ignored it all and became the world&#39;s best
player by just playing against itself.
											And the most impressive feat here
wasn&#39;t that it crushed human gamers,
											but that it crushed human AI researchers
											who had spent decades
handcrafting game-playing software.
											And AlphaZero crushed human AI researchers
not just in Go but even at chess,
											which we have been working on since 1950.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											So all this amazing recent progress in AI
really begs the question:
											How far will it go?
											I like to think about this question
											in terms of this abstract
landscape of tasks,
											where the elevation represents
how hard it is for AI to do each task
											at human level,
											and the sea level represents
what AI can do today.
											The sea level is rising
as AI improves,
											so there&#39;s a kind of global warming
going on here in the task landscape.
											And the obvious takeaway
is to avoid careers at the waterfront —
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											(Laughter)
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											which will soon be
automated and disrupted.
											But there&#39;s a much
bigger question as well.
											How high will the water end up rising?
											Will it eventually rise
to flood everything,
											matching human intelligence at all tasks.
											This is the definition
of artificial general intelligence —
											AGI,
											which has been the holy grail
of AI research since its inception.
											By this definition, people who say,
											&quot;Ah, there will always be jobs
that humans can do better than machines,&quot;
											are simply saying
that we&#39;ll never get AGI.
											Sure, we might still choose
to have some human jobs
											or to give humans income
and purpose with our jobs,
											but AGI will in any case
transform life as we know it
											with humans no longer being
the most intelligent.
											Now, if the water level does reach AGI,
											then further AI progress will be driven
mainly not by humans but by AI,
											which means that there&#39;s a possibility
											that further AI progress
could be way faster
											than the typical human research
and development timescale of years,
											raising the controversial possibility
of an intelligence explosion
											where recursively self-improving AI
											rapidly leaves human
intelligence far behind,
											creating what&#39;s known
as superintelligence.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											Alright, reality check:
											Are we going to get AGI any time soon?
											Some famous AI researchers,
like Rodney Brooks,
											think it won&#39;t happen
for hundreds of years.
											But others, like Google DeepMind
founder Demis Hassabis,
											are more optimistic
											and are working to try to make
it happen much sooner.
											And recent surveys have shown
that most AI researchers
											actually share Demis&#39;s optimism,
											expecting that we will
get AGI within decades,
											so within the lifetime of many of us,
											which begs the question — and then what?
											What do we want the role of humans to be
											if machines can do everything better
and cheaper than us?
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											The way I see it, we face a choice.
											One option is to be complacent.
											We can say, &quot;Oh, let&#39;s just build machines
that can do everything we can do
											and not worry about the consequences.
											Come on, if we build technology
that makes all humans obsolete,
											what could possibly go wrong?&quot;
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											(Laughter)
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											But I think that would be
embarrassingly lame.
											I think we should be more ambitious —
in the spirit of TED.
											Let&#39;s envision a truly inspiring
high-tech future
											and try to steer towards it.
											This brings us to the second part
of our rocket metaphor: the steering.
											We&#39;re making AI more powerful,
											but how can we steer towards a future
											where AI helps humanity flourish
rather than flounder?
											To help with this,
											I cofounded the Future of Life Institute.
											It&#39;s a small nonprofit promoting
beneficial technology use,
											and our goal is simply
for the future of life to exist
											and to be as inspiring as possible.
											You know, I love technology.
											Technology is why today
is better than the Stone Age.
											And I&#39;m optimistic that we can create
a really inspiring high-tech future ...
											if — and this is a big if —
											if we win the wisdom race —
											the race between the growing
power of our technology
											and the growing wisdom
with which we manage it.
											But this is going to require
a change of strategy
											because our old strategy
has been learning from mistakes.
											We invented fire,
											screwed up a bunch of times —
											invented the fire extinguisher.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											(Laughter)
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											We invented the car,
screwed up a bunch of times —
											invented the traffic light,
the seat belt and the airbag,
											but with more powerful technology
like nuclear weapons and AGI,
											learning from mistakes
is a lousy strategy,
											don&#39;t you think?
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											(Laughter)
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											It&#39;s much better to be proactive
rather than reactive;
											plan ahead and get things
right the first time
											because that might be
the only time we&#39;ll get.
											But it is funny because
sometimes people tell me,
											&quot;Max, shhh, don&#39;t talk like that.
											That&#39;s Luddite scaremongering.&quot;
											But it&#39;s not scaremongering.
											It&#39;s what we at MIT
call safety engineering.
											Think about it:
											before NASA launched
the Apollo 11 mission,
											they systematically thought through
everything that could go wrong
											when you put people
on top of explosive fuel tanks
											and launch them somewhere
where no one could help them.
											And there was a lot that could go wrong.
											Was that scaremongering?
											No.
											That&#39;s was precisely
the safety engineering
											that ensured the success of the mission,
											and that is precisely the strategy
I think we should take with AGI.
											Think through what can go wrong
to make sure it goes right.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											So in this spirit,
we&#39;ve organized conferences,
											bringing together leading
AI researchers and other thinkers
											to discuss how to grow this wisdom
we need to keep AI beneficial.
											Our last conference
was in Asilomar, California last year
											and produced this list of 23 principles
											which have since been signed
by over 1,000 AI researchers
											and key industry leaders,
											and I want to tell you
about three of these principles.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											One is that we should avoid an arms race
and lethal autonomous weapons.
											The idea here is that any science
can be used for new ways of helping people
											or new ways of harming people.
											For example, biology and chemistry
are much more likely to be used
											for new medicines or new cures
than for new ways of killing people,
											because biologists
and chemists pushed hard —
											and successfully —
											for bans on biological
and chemical weapons.
											And in the same spirit,
											most AI researchers want to stigmatize
and ban lethal autonomous weapons.
											Another Asilomar AI principle
											is that we should mitigate
AI-fueled income inequality.
											I think that if we can grow
the economic pie dramatically with AI
											and we still can&#39;t figure out
how to divide this pie
											so that everyone is better off,
											then shame on us.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											(Applause)
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											Alright, now raise your hand
if your computer has ever crashed.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											(Laughter)
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											Wow, that&#39;s a lot of hands.
											Well, then you&#39;ll appreciate
this principle
											that we should invest much more
in AI safety research,
											because as we put AI in charge
of even more decisions and infrastructure,
											we need to figure out how to transform
today&#39;s buggy and hackable computers
											into robust AI systems
that we can really trust,
											because otherwise,
											all this awesome new technology
can malfunction and harm us,
											or get hacked and be turned against us.
											And this AI safety work
has to include work on AI value alignment,
											because the real threat
from AGI isn&#39;t malice,
											like in silly Hollywood movies,
											but competence —
											AGI accomplishing goals
that just aren&#39;t aligned with ours.
											For example, when we humans drove
the West African black rhino extinct,
											we didn&#39;t do it because we were a bunch
of evil rhinoceros haters, did we?
											We did it because
we were smarter than them
											and our goals weren&#39;t aligned with theirs.
											But AGI is by definition smarter than us,
											so to make sure that we don&#39;t put
ourselves in the position of those rhinos
											if we create AGI,
											we need to figure out how
to make machines understand our goals,
											adopt our goals and retain our goals.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											And whose goals should these be, anyway?
											Which goals should they be?
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											This brings us to the third part
of our rocket metaphor: the destination.
											We&#39;re making AI more powerful,
											trying to figure out how to steer it,
											but where do we want to go with it?
											This is the elephant in the room
that almost nobody talks about —
											not even here at TED —
											because we&#39;re so fixated
on short-term AI challenges.
											Look, our species is trying to build AGI,
											motivated by curiosity and economics,
											but what sort of future society
are we hoping for if we succeed?
											We did an opinion poll on this recently,
											and I was struck to see
											that most people actually
want us to build superintelligence:
											AI that&#39;s vastly smarter
than us in all ways.
											What there was the greatest agreement on
was that we should be ambitious
											and help life spread into the cosmos,
											but there was much less agreement
about who or what should be in charge.
											And I was actually quite amused
											to see that there&#39;s some some people
who want it to be just machines.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											(Laughter)
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											And there was total disagreement
about what the role of humans should be,
											even at the most basic level,
											so let&#39;s take a closer look
at possible futures
											that we might choose
to steer toward, alright?
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											So don&#39;t get me wrong here.
											I&#39;m not talking about space travel,
											merely about humanity&#39;s
metaphorical journey into the future.
											So one option that some
of my AI colleagues like
											is to build superintelligence
and keep it under human control,
											like an enslaved god,
											disconnected from the internet
											and used to create unimaginable
technology and wealth
											for whoever controls it.
											But Lord Acton warned us
											that power corrupts,
and absolute power corrupts absolutely,
											so you might worry that maybe
we humans just aren&#39;t smart enough,
											or wise enough rather,
											to handle this much power.
											Also, aside from any
moral qualms you might have
											about enslaving superior minds,
											you might worry that maybe
the superintelligence could outsmart us,
											break out and take over.
											But I also have colleagues
who are fine with AI taking over
											and even causing human extinction,
											as long as we feel the the AIs
are our worthy descendants,
											like our children.
											But how would we know that the AIs
have adopted our best values
											and aren&#39;t just unconscious zombies
tricking us into anthropomorphizing them?
											Also, shouldn&#39;t those people
who don&#39;t want human extinction
											have a say in the matter, too?
											Now, if you didn&#39;t like either
of those two high-tech options,
											it&#39;s important to remember
that low-tech is suicide
											from a cosmic perspective,
											because if we don&#39;t go far
beyond today&#39;s technology,
											the question isn&#39;t whether humanity
is going to go extinct,
											merely whether
we&#39;re going to get taken out
											by the next killer asteroid, supervolcano
											or some other problem
that better technology could have solved.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											So, how about having
our cake and eating it ...
											with AGI that&#39;s not enslaved
											but treats us well because its values
are aligned with ours?
											This is the gist of what Eliezer Yudkowsky
has called &quot;friendly AI,&quot;
											and if we can do this,
it could be awesome.
											It could not only eliminate negative
experiences like disease, poverty,
											crime and other suffering,
											but it could also give us
the freedom to choose
											from a fantastic new diversity
of positive experiences —
											basically making us
the masters of our own destiny.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											So in summary,
											our situation with technology
is complicated,
											but the big picture is rather simple.
											Most AI researchers
expect AGI within decades,
											and if we just bumble
into this unprepared,
											it will probably be
the biggest mistake in human history —
											let&#39;s face it.
											It could enable brutal,
global dictatorship
											with unprecedented inequality,
surveillance and suffering,
											and maybe even human extinction.
											But if we steer carefully,
											we could end up in a fantastic future
where everybody&#39;s better off:
											the poor are richer, the rich are richer,
											everybody is healthy
and free to live out their dreams.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											Now, hang on.
											Do you folks want the future
that&#39;s politically right or left?
											Do you want the pious society
with strict moral rules,
											or do you an hedonistic free-for-all,
											more like Burning Man 24/7?
											Do you want beautiful beaches,
forests and lakes,
											or would you prefer to rearrange
some of those atoms with the computers,
											enabling virtual experiences?
											With friendly AI, we could simply
build all of these societies
											and give people the freedom
to choose which one they want to live in
											because we would no longer
be limited by our intelligence,
											merely by the laws of physics.
											So the resources and space
for this would be astronomical —
											literally.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											So here&#39;s our choice.
											We can either be complacent
about our future,
											taking as an article of blind faith
											that any new technology
is guaranteed to be beneficial,
											and just repeat that to ourselves
as a mantra over and over and over again
											as we drift like a rudderless ship
towards our own obsolescence.
											Or we can be ambitious —
											thinking hard about how
to steer our technology
											and where we want to go with it
											to create the age of amazement.
											We&#39;re all here to celebrate
the age of amazement,
											and I feel that its essence should lie
in becoming not overpowered
											but empowered by our technology.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											Thank you.
									</p>
								</div>
							</div>
													<div class="Grid Grid--with-gutter d:f@md p-b:4">
								<div class="Grid__cell d:f h:full m-b:.5 m-b:0@md w:12"></div>

								<div class="Grid__cell flx-s:1 p-r:4">
									<p>
											(Applause)
									</p>
								</div>
							</div>
						<!-- /Transcript text -->

					</div>
				</div><!-- /Text container -->

			</div><!-- /Main column -->

			<!-- Sidebar -->
			<div class="Grid__cell w:1of3@md"></div>

		</div>
	</div>
</div>

		</div>
	</div>

<script data-spec="q">q("talkPage.init",{"el":"[data-talk-page]","__INITIAL_DATA__":{"comments":{"id":27994,"count":39,"talk_id":17851},"threadId":27994,"requested_language_english_name":"English","current_talk":"17851","description":"Many artificial intelligence researchers expect AI to outsmart humans at all tasks and jobs within decades, enabling a future where we're restricted only by the laws of physics, not the limits of our intelligence. MIT physicist and AI researcher Max Tegmark separates the real opportunities and threats from the myths, describing the concrete steps we should take today to ensure that AI ends up being the best -- rather than worst -- thing to ever happen to humanity.","event":"TED2018","language":"en","language_swap":false,"name":"Max Tegmark: How to get empowered, not overpowered, by AI","slug":"max_tegmark_how_to_get_empowered_not_overpowered_by_ai","series_slug":null,"speakers":[{"id":"3942","slug":"max_tegmark","is_published":true,"firstname":"Max","lastname":"Tegmark","middleinitial":"","title":"","description":"Scientist, author","photo_url":"https://pe.tedcdn.com/images/ted/30749111506edf399fa849e6787e757365800ad3_254x191.jpg","whatotherssay":"","whotheyare":"Max Tegmark is driven by curiosity, both about how our universe works and about how we can use the science and technology we discover to help humanity flourish rather than flounder.","whylisten":"<p>Max Tegmark is an MIT professor who loves thinking about life&#39;s big questions. He&#39;s written two popular books,&nbsp;<a href=\"https://www.amazon.com/Our-Mathematical-Universe-Ultimate-Reality/dp/0307744256\" target=\"_blank\"><em>Our Mathematical Universe: My Quest for the Ultimate Nature of Reality</em></a> and the recently published&nbsp;<em><a href=\"https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598\" target=\"_blank\">Life 3.0: Being Human in the Age of Artificial Intelligence</a>,&nbsp;</em>as well as more than 200 <a href=\"http://space.mit.edu/home/tegmark/technical.html\" target=\"_blank\">nerdy technical papers</a> on topics from cosmology to AI.</p><p>He writes: &quot;In my spare time, I&#39;m president of the <a href=\"https://futureoflife.org/\" target=\"_blank\">Future of Life Institute</a>, which aims to ensure that we develop not only technology&nbsp;but also the wisdom required to use it beneficially.&quot;</p>"}],"url":"https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai","viewed_count":1385199,"talks":[{"recommendations":{"status":"approved","headline":"Max Tegmark recommends","blurb":"More resources curated by Max Tegmark","start_at":null,"end_at":null,"published":true,"eyebrow":"","type":"recommendation","rec_lists":[{"title":"","description":"","rec_items":[{"label":"READ_Book","headline":"*Life 3.0: Being Human in the Age of Artificial Intelligence*","blurb":"This is the book where I go into depth on all the issues raised in my TED talk. I wrote it to empower you to join what may be the most important conversation of our time. It doesn't shy away from the full range of viewpoints or from the most controversial issues -- from superintelligence to meaning, consciousness and the ultimate physical limits on life in the cosmos.","note":"Max Tegmark\r\nKnopf, 2017","link_url":"https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20","position":null,"is_pdf":false,"eyebrow":""},{"label":"READ_Book","headline":"*The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies*","blurb":"This engaging and thought-provoking book, two of the world's leading economists separate the myths from the facts regarding AI's massive upcoming impact on the job market -- and give useful advice about how to make the best of it both for you personally and for policymakers.","note":"Erik Brynjolfsson and Andrew McAfee\r\nNorton, 2014","link_url":"https://www.amazon.com/Second-Machine-Age-Prosperity-Technologies/dp/0393350649/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20","position":null,"is_pdf":false,"eyebrow":""},{"label":"READ_Book","headline":"*Superintelligence: Paths, Dangers, Strategies*","blurb":"This is the book that helped propel the discussion of existential threats from AI from back rooms into the academic mainstream. Although the style of the book is rather academic, it’s the perfect resource for anyone who appreciates rigorous arguments and yearns for a deeper dive into the most important long-term issue of our time.","note":"Nick Bostrom\r\nOxfird University Press, 2014","link_url":"https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0198739834/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20","position":null,"is_pdf":false,"eyebrow":""},{"label":"WATCH","headline":"\"Slaughterbots\"","blurb":"Brief video illustrating an AI future we should try to avoid by stigmatizing lethal autonomous weapons. ","note":"Future of Life Institute\r\nYouTube, 2017","link_url":"https://www.youtube.com/watch?v=9CO6M2HsoIA","position":null,"is_pdf":false,"eyebrow":""},{"label":"EXPLORE","headline":"The universes of Max Tegmark","blurb":"Popular articles, videos and research by Max Tegmark","note":"Future of Life Institute\r\nYouTube, 2017","link_url":"http://space.mit.edu/home/tegmark/","position":null,"is_pdf":false,"eyebrow":""}]}]},"more_resources":[{"status":"approved","headline":"*Life 3.0: Being Human in the Age of Artificial Intelligence*","blurb":null,"link_url":"https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20","image_url":"https://pe.tedcdn.com/images/ted/acc14e6541b61ba42ce599ea138c890a1a44a012_1735x2560.jpg","author":"Max Tegmark","year":"2017","publisher":"Knopf","start_at":null,"end_at":null,"published":true,"eyebrow":"","type":"book"}],"corrections":[],"has_citations":false,"take_action":[],"explore_cta_experiment":{},"curator_approved":true,"description":"Many artificial intelligence researchers expect AI to outsmart humans at all tasks and jobs within decades, enabling a future where we're restricted only by the laws of physics, not the limits of our intelligence. MIT physicist and AI researcher Max Tegmark separates the real opportunities and threats from the myths, describing the concrete steps we should take today to ensure that AI ends up being the best -- rather than worst -- thing to ever happen to humanity.","downloads":{"id":17851,"languages":[{"languageName":"English","endonym":"English","languageCode":"en","ianaCode":"en","isRtl":false},{"languageName":"Spanish","endonym":"Español","languageCode":"es","ianaCode":"es","isRtl":false},{"languageName":"Portuguese, Brazilian","endonym":"Português brasileiro","languageCode":"pt-br","ianaCode":"pt-BR","isRtl":false},{"languageName":"Portuguese","endonym":"Português de Portugal","languageCode":"pt","ianaCode":"pt","isRtl":false},{"languageName":"Korean","endonym":"한국어","languageCode":"ko","ianaCode":"ko","isRtl":false},{"languageName":"Russian","endonym":"Русский","languageCode":"ru","ianaCode":"ru","isRtl":false},{"languageName":"Chinese, Simplified","endonym":"中文 (简体)","languageCode":"zh-cn","ianaCode":"zh-Hans","isRtl":false},{"languageName":"Turkish","endonym":"Türkçe","languageCode":"tr","ianaCode":"tr","isRtl":false},{"languageName":"Japanese","endonym":"日本語","languageCode":"ja","ianaCode":"ja","isRtl":false},{"languageName":"Italian","endonym":"Italiano","languageCode":"it","ianaCode":"it","isRtl":false},{"languageName":"Dutch","endonym":"Nederlands","languageCode":"nl","ianaCode":"nl","isRtl":false},{"languageName":"Thai","endonym":"ภาษาไทย","languageCode":"th","ianaCode":"th","isRtl":false},{"languageName":"Persian","endonym":"فارسى","languageCode":"fa","ianaCode":"fa","isRtl":true},{"languageName":"Chinese, Traditional","endonym":"中文 (繁體)","languageCode":"zh-tw","ianaCode":"zh-Hant","isRtl":false},{"languageName":"German","endonym":"Deutsch","languageCode":"de","ianaCode":"de","isRtl":false},{"languageName":"Arabic","endonym":"العربية","languageCode":"ar","ianaCode":"ar","isRtl":true},{"languageName":"Kurdish","endonym":"کوردی","languageCode":"ku","ianaCode":"ku","isRtl":true},{"languageName":"Hungarian","endonym":"Magyar","languageCode":"hu","ianaCode":"hu","isRtl":false},{"languageName":"French","endonym":"Français","languageCode":"fr","ianaCode":"fr","isRtl":false},{"languageName":"Vietnamese","endonym":"Tiếng Việt","languageCode":"vi","ianaCode":"vi","isRtl":false}],"nativeDownloads":{"low":"https://download.ted.com/talks/MaxTegmark_2018-light.mp4?apikey=acme-roadrunner","medium":"https://download.ted.com/talks/MaxTegmark_2018.mp4?apikey=acme-roadrunner","high":"https://download.ted.com/talks/MaxTegmark_2018-480p.mp4?apikey=acme-roadrunner"},"subtitledDownloads":{"en":{"name":"English","low":"https://download.ted.com/talks/MaxTegmark_2018-low-en.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-en.mp4"},"es":{"name":"Spanish","low":"https://download.ted.com/talks/MaxTegmark_2018-low-es.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-es.mp4"},"pt-br":{"name":"Portuguese, Brazilian","low":"https://download.ted.com/talks/MaxTegmark_2018-low-pt-br.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-pt-br.mp4"},"pt":{"name":"Portuguese","low":"https://download.ted.com/talks/MaxTegmark_2018-low-pt.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-pt.mp4"},"ko":{"name":"Korean","low":"https://download.ted.com/talks/MaxTegmark_2018-low-ko.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-ko.mp4"},"ru":{"name":"Russian","low":"https://download.ted.com/talks/MaxTegmark_2018-low-ru.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-ru.mp4"},"zh-cn":{"name":"Chinese, Simplified","low":"https://download.ted.com/talks/MaxTegmark_2018-low-zh-cn.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-zh-cn.mp4"},"tr":{"name":"Turkish","low":"https://download.ted.com/talks/MaxTegmark_2018-low-tr.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-tr.mp4"},"ja":{"name":"Japanese","low":"https://download.ted.com/talks/MaxTegmark_2018-low-ja.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-ja.mp4"},"it":{"name":"Italian","low":"https://download.ted.com/talks/MaxTegmark_2018-low-it.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-it.mp4"},"nl":{"name":"Dutch","low":"https://download.ted.com/talks/MaxTegmark_2018-low-nl.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-nl.mp4"},"th":{"name":"Thai","low":"https://download.ted.com/talks/MaxTegmark_2018-low-th.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-th.mp4"},"fa":{"name":"Persian","low":"https://download.ted.com/talks/MaxTegmark_2018-low-fa.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-fa.mp4"},"zh-tw":{"name":"Chinese, Traditional","low":"https://download.ted.com/talks/MaxTegmark_2018-low-zh-tw.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-zh-tw.mp4"},"de":{"name":"German","low":"https://download.ted.com/talks/MaxTegmark_2018-low-de.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-de.mp4"},"ar":{"name":"Arabic","low":"https://download.ted.com/talks/MaxTegmark_2018-low-ar.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-ar.mp4"},"hu":{"name":"Hungarian","low":"https://download.ted.com/talks/MaxTegmark_2018-low-hu.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-hu.mp4"},"fr":{"name":"French","low":"https://download.ted.com/talks/MaxTegmark_2018-low-fr.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-fr.mp4"},"vi":{"name":"Vietnamese","low":"https://download.ted.com/talks/MaxTegmark_2018-low-vi.mp4","high":"https://download.ted.com/talks/MaxTegmark_2018-480p-vi.mp4"}},"audioDownload":"https://download.ted.com/talks/MaxTegmark_2018.mp3?apikey=acme-roadrunner"},"duration":1035.0,"event":"TED2018","institute_partner_name":null,"salon_partner_name":null,"event_badge":null,"is_featured":true,"hero":"https://s3.amazonaws.com/talkstar-photos/uploads/fb47cef7-3332-4841-8057-a7544548d607/MaxTegmark_2018-embed.jpg","hero_load":"https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/fb47cef7-3332-4841-8057-a7544548d607/MaxTegmark_2018-embed.jpg?q=50&w=15","id":"17851","player_talks":[{"id":"17851","mediaIdentifier":"MaxTegmark_2018","duration":1035.0,"languages":[{"languageName":"English","endonym":"English","languageCode":"en","ianaCode":"en","isRtl":false},{"languageName":"Spanish","endonym":"Español","languageCode":"es","ianaCode":"es","isRtl":false},{"languageName":"Portuguese, Brazilian","endonym":"Português brasileiro","languageCode":"pt-br","ianaCode":"pt-BR","isRtl":false},{"languageName":"Portuguese","endonym":"Português de Portugal","languageCode":"pt","ianaCode":"pt","isRtl":false},{"languageName":"Korean","endonym":"한국어","languageCode":"ko","ianaCode":"ko","isRtl":false},{"languageName":"Russian","endonym":"Русский","languageCode":"ru","ianaCode":"ru","isRtl":false},{"languageName":"Chinese, Simplified","endonym":"中文 (简体)","languageCode":"zh-cn","ianaCode":"zh-Hans","isRtl":false},{"languageName":"Turkish","endonym":"Türkçe","languageCode":"tr","ianaCode":"tr","isRtl":false},{"languageName":"Japanese","endonym":"日本語","languageCode":"ja","ianaCode":"ja","isRtl":false},{"languageName":"Italian","endonym":"Italiano","languageCode":"it","ianaCode":"it","isRtl":false},{"languageName":"Dutch","endonym":"Nederlands","languageCode":"nl","ianaCode":"nl","isRtl":false},{"languageName":"Thai","endonym":"ภาษาไทย","languageCode":"th","ianaCode":"th","isRtl":false},{"languageName":"Persian","endonym":"فارسى","languageCode":"fa","ianaCode":"fa","isRtl":true},{"languageName":"Chinese, Traditional","endonym":"中文 (繁體)","languageCode":"zh-tw","ianaCode":"zh-Hant","isRtl":false},{"languageName":"German","endonym":"Deutsch","languageCode":"de","ianaCode":"de","isRtl":false},{"languageName":"Arabic","endonym":"العربية","languageCode":"ar","ianaCode":"ar","isRtl":true},{"languageName":"Kurdish","endonym":"کوردی","languageCode":"ku","ianaCode":"ku","isRtl":true},{"languageName":"Hungarian","endonym":"Magyar","languageCode":"hu","ianaCode":"hu","isRtl":false},{"languageName":"French","endonym":"Français","languageCode":"fr","ianaCode":"fr","isRtl":false},{"languageName":"Vietnamese","endonym":"Tiếng Việt","languageCode":"vi","ianaCode":"vi","isRtl":false}],"nativeLanguage":"en","isSubtitleRequired":false,"introDuration":11.82,"adDuration":3.33,"postAdDuration":0.83,"resources":{"h264":[{"bitrate":180,"file":"https://pc.tedcdn.com/talk/stream/2018/Blank/MaxTegmark_2018-180k.mp4?dnt"}],"hls":{"adUrl":"https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTED2018%26id%3D17851%26tag%3DAI%2Cfuture%2Ctechnology%2Chumanity%2Cmachine%2Blearning%2Cinnovation%2Cintelligence%2Csociety%2Ccomputers%26talk%3Dmax_tegmark_how_to_get_empowered_not_overpowered_by_ai%26year%3D2018&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D","maiTargeting":{"id":"17851","talk":"max_tegmark_how_to_get_empowered_not_overpowered_by_ai","tag":"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers","year":"2018","event":"TED2018"},"stream":"https://hls.ted.com/talks/17851.m3u8","metadata":"https://hls.ted.com/talks/17851.json"}},"targeting":{"id":"17851","talk":"max_tegmark_how_to_get_empowered_not_overpowered_by_ai","tag":"AI,future,technology,humanity,machine learning,innovation,intelligence,society,computers","year":"2018","event":"TED2018"},"canonical":"https://www.ted.com/talks/max_tegmark_how_to_get_empowered_not_overpowered_by_ai","name":"Max Tegmark: How to get empowered, not overpowered, by AI","title":"How to get empowered, not overpowered, by AI","speaker":"Max Tegmark","thumb":"https://pi.tedcdn.com/r/talkstar-photos.s3.amazonaws.com/uploads/fb47cef7-3332-4841-8057-a7544548d607/MaxTegmark_2018-embed.jpg?quality=89&w=600","slug":"max_tegmark_how_to_get_empowered_not_overpowered_by_ai","event":"TED2018","published":1528901718}],"recorded_at":"2018-04-10T00:00:00.000+00:00","related_talks":[{"id":"2243","hero":"https://pe.tedcdn.com/images/ted/a693e3148df55358b76a30436f1accb09d1e2616_2880x1620.jpg","speaker":"Nick Bostrom","title":"What happens when our computers get smarter than we are?","duration":991.0,"slug":"nick_bostrom_what_happens_when_our_computers_get_smarter_than_we_are","viewed_count":4402643},{"id":"3633","hero":"https://s3.amazonaws.com/talkstar-photos/uploads/78d90be3-3fb2-4b34-88f1-b9618ce26159/SebastianThrun_2017-embed.jpg","speaker":"Sebastian Thrun and Chris Anderson","title":"What AI is -- and isn't","duration":1461.0,"slug":"sebastian_thrun_and_chris_anderson_the_new_generation_of_computers_is_programming_itself","viewed_count":1549393},{"id":"2841","hero":"https://s3.amazonaws.com/talkstar-photos/uploads/a97a1a9e-7fea-4ccd-a957-6611044b19dd/TomGruber_2017-embed.jpg","speaker":"Tom Gruber","title":"How AI can enhance our memory, work and social lives","duration":586.0,"slug":"tom_gruber_how_ai_can_enhance_our_memory_work_and_social_lives","viewed_count":1992890},{"id":"2645","hero":"https://s3.amazonaws.com/talkstar-photos/uploads/2c01d3e9-fdcb-4fc7-b7d9-303a38ff2981/KevinKelly_2016T-embed.jpg","speaker":"Kevin Kelly","title":"How AI can bring on a second Industrial Revolution","duration":824.0,"slug":"kevin_kelly_how_ai_can_bring_on_a_second_industrial_revolution","viewed_count":1710548},{"id":"36479","hero":"https://s3.amazonaws.com/talkstar-photos/uploads/441028fd-5018-4a46-9ac7-2389b7e2c3d5/KritiSharma_2018X-embed.jpg","speaker":"Kriti Sharma","title":"How to keep human bias out of AI","duration":730.0,"slug":"kriti_sharma_how_to_keep_human_biases_out_of_ai","viewed_count":1795190},{"id":"2592","hero":"https://s3.amazonaws.com/talkstar-photos/uploads/51c9b741-275c-4ea0-bb9d-11b9aa8d1165/SamHarris_2016T-embed.jpg","speaker":"Sam Harris","title":"Can we build AI without losing control over it?","duration":867.0,"slug":"sam_harris_can_we_build_ai_without_losing_control_over_it","viewed_count":4687836}],"slug":"max_tegmark_how_to_get_empowered_not_overpowered_by_ai","speakers":[{"id":"3942","slug":"max_tegmark","is_published":true,"firstname":"Max","lastname":"Tegmark","middleinitial":"","title":"","description":"Scientist, author","photo_url":"https://pe.tedcdn.com/images/ted/30749111506edf399fa849e6787e757365800ad3_254x191.jpg","whatotherssay":"","whotheyare":"Max Tegmark is driven by curiosity, both about how our universe works and about how we can use the science and technology we discover to help humanity flourish rather than flounder.","whylisten":"<p>Max Tegmark is an MIT professor who loves thinking about life&#39;s big questions. He&#39;s written two popular books,&nbsp;<a href=\"https://www.amazon.com/Our-Mathematical-Universe-Ultimate-Reality/dp/0307744256\" target=\"_blank\"><em>Our Mathematical Universe: My Quest for the Ultimate Nature of Reality</em></a> and the recently published&nbsp;<em><a href=\"https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598\" target=\"_blank\">Life 3.0: Being Human in the Age of Artificial Intelligence</a>,&nbsp;</em>as well as more than 200 <a href=\"http://space.mit.edu/home/tegmark/technical.html\" target=\"_blank\">nerdy technical papers</a> on topics from cosmology to AI.</p><p>He writes: &quot;In my spare time, I&#39;m president of the <a href=\"https://futureoflife.org/\" target=\"_blank\">Future of Life Institute</a>, which aims to ensure that we develop not only technology&nbsp;but also the wisdom required to use it beneficially.&quot;</p>"}],"speaker_name":"Max Tegmark","tags":["AI","future","technology","humanity","machine learning","innovation","intelligence","society","computers"],"title":"How to get empowered, not overpowered, by AI","video_type":{"id":"1","name":"TED Stage Talk"},"viewed_count":1385199}]}})</script></div>
<footer class='footer'>
<div class='container'>
<div class='footer__content'>
<a class="g-logo-small footer__logo" href="/">TED</a>
<div class='footer__content__links'>
<nav class='footer__section' role='navigation'>
<h3 class='footer__title'>
Programs &amp; initiatives
</h3>
<ul class='footer__links'>
<li class='m5'><a class="footer__link" href="/about/programs-initiatives/tedx-program">TEDx</a></li>
<li class='m5'><a class="footer__link" href="/about/programs-initiatives/ted-prize">TED Prize</a></li>
<li class='m5'><a class="footer__link" href="/about/programs-initiatives/ted-fellows-program">TED Fellows</a></li>
<li class='m5'><a class="footer__link" href="/about/programs-initiatives/ted-ed">TED Ed</a></li>
<li class='m5'><a class="footer__link" href="/about/programs-initiatives/ted-translators">TED Translators</a></li>
<li class='m5'><a class="footer__link" href="/about/programs-initiatives/ted-books">TED Books</a></li>
<li class='m5'><a class="footer__link" href="/about/programs-initiatives/ted-institute">TED Institute</a></li>
</ul>
</nav>
<nav class='footer__section' role='navigation'>
<h3 class='footer__title'>
Ways to get TED
</h3>
<ul class='footer__links'>
<li class='m5'><a class="footer__link" href="/podcasts">Podcasts</a></li>
<li class='m5'><a class="footer__link" href="/about/programs-initiatives/ted-talks/ways-to-get-ted-talks">More ways to get TED</a></li>
</ul>
</nav>
<nav class='footer__section' role='navigation'>
<h3 class='footer__title'>Follow TED</h3>
<ul class='footer__links'>
<li class='m5'><a class="footer__link" target="_blank" href="https://www.facebook.com/TED">Facebook</a></li>
<li class='m5'><a class="footer__link" target="_blank" href="https://twitter.com/tedtalks">Twitter</a></li>
<li class='m5'><a class="footer__link" target="_blank" href="https://www.pinterest.com/tednews">Pinterest</a></li>
<li class='m5'><a class="footer__link" target="_blank" href="https://instagram.com/ted">Instagram</a></li>
<li class='m5'><a class="footer__link" target="_blank" href="https://www.youtube.com/ted">YouTube</a></li>
<li><a class="footer__link" href="https://blog.ted.com">TED Blog</a></li>
</ul>
</nav>
<nav class='footer__section' role='navigation'>
<h3 class='footer__title'>Our community</h3>
<ul class='footer__links'>
<li class='m5'><a class="footer__link" href="/people/speakers">TED Speakers</a></li>
<li class='m5'><a class="footer__link" href="/people/fellows">TED Fellows</a></li>
<li class='m5'><a class="footer__link" href="/people/translators">TED Translators</a></li>
<li class='m5'><a class="footer__link" rel="nofollow" href="/people/tedx">TEDx Organizers</a></li>
<li class='m5'><a class="footer__link" href="/people">TED Community</a></li>
</ul>
</nav>
</div>
<div class='footer__content__forms'>
<form class='footer-newsletter footer__section footer__section--form p-r:.8'>
<h3 class='footer__title'>Want personalized recommendations?</h3>
<div class='c:black f:.9 m-b:2'>
Join
<span class='f-w:700'>
TED Recommends
</span>
and get the perfect ideas selected just for you.
</div>
<a class='ga-link bg:gray-dd b-r:.2 c:white hover/c:white d:i-b f:1 f-w:700 p-y:1 p-x:4 t-d:n' data-ga-action='getStarted' data-ga-category='footer' data-ga-label='recommends' href='/recommends?exploreCTASource=footer.link'>
Get started
</a>
</form>
<form class='footer__section' style='display:none;'>
<h3 class='footer__title'>Language Selector</h3>
<p>TED.com translations are made possible by volunteer
translators. Learn more about the
<a href="/pages/open_translation_project">Open Translation Project</a>.</p>
<select class='form-control' disabled>
<option>English</option>
</select>
</form>
</div>
</div>
</div>
<div class='footer__services'>
<div class='container footer__services__container'>
<nav role='navigation'>
<ul class='footer__links'>
<li><a class="footer__service" href="/about/our-organization/our-policies-terms/ted-talks-usage-policy">TED Talks Usage Policy</a></li>
<li><a class="footer__service" href="/about/our-organization/our-policies-terms/privacy-policy">Privacy Policy</a></li>
<li><a class="footer__service" href="/about/partner-with-ted">Advertising / Partnership</a></li>
<li><a class="footer__service" href="/about/our-organization/our-policies-terms/ted-com-terms-of-use">TED.com Terms of Use</a></li>
<li><a class="footer__service" href="/about/our-organization/jobs-at-ted">Jobs</a></li>
<li><a class="footer__service" href="/about/our-organization/contact-us/press-and-media-information">Press</a></li>
<li><a class="footer__service" href="https://support.ted.com ">Help</a></li>
</ul>
</nav>
<p class='footer__service footer__service--info' role='contentinfo'>
&copy; TED Conferences, LLC. All rights reserved.
</p>
</div>
</div>
</footer></div>
<a class='shoji__lattice' href='#' id='shoji-lattice'></a>
</div>
</div>
<div id="activity-feed" style="position: relative;"></div>
<script>g("activityFeed","#activity-feed",{})</script><script src='https://pa.tedcdn.com/javascripts/screens/manifest-9457bf12f7446ef27b14.js'></script>
<script src='https://pa.tedcdn.com/javascripts/screens/22cc1a63fe14e153e41f.chunk.js'></script>
<script async src='https://pa.tedcdn.com/javascripts/screens/af13f91547c728110d56.chunk.js'></script><script>
  (function() {
    var gads = document.createElement("script");
    gads.async = true;
    gads.type = "text/javascript";
    gads.src = 'https://securepubads.g.doubleclick.net/tag/js/gpt.js';
    var node = document.getElementsByTagName("script")[0];
    node.parentNode.insertBefore(gads, node);
  })();
</script><script>
  (function(s,o,b,a,m){
    a=s.createElement(o),m=s.getElementsByTagName(o)[0];
    a.async=1;a.src=b;
    m.parentNode.insertBefore(a,m)
  })(document,'script','https://www.google-analytics.com/analytics.js');
</script><script>
  var _comscore = _comscore || [];
  _comscore.push({ c1: "2", c2: "7341760" });
  (function() {
    var s = document.createElement("script"), el = document.getElementsByTagName("script")[0]; s.async = true;
    s.src = (document.location.protocol == "https:" ? "https://sb" : "http://b") + ".scorecardresearch.com/beacon.js";
    el.parentNode.insertBefore(s, el);
  })();
</script><script>
  (function(d,s,u,e,m,r){r=(d.location.search||'').match(/[?&](geo=[A-Z]{2})\b/);e=d.createElement(s),m=d.getElementsByTagName(s)[0];e.async=1;e.src=u+(r?'&'+r[1]:'');m.parentNode.insertBefore(e,m)})(document,'script','https://geo-assets.tedcdn.com/cookie-notice/tcn.js?cb=1.1.4')
</script></body></html>