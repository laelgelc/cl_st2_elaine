Human language, mathematics, logic. These are all ways to formalize the world. And in our century, there's a new and yet more powerful one: computation. For nearly 50 years, I've had the great privilege of building up an ever-taller tower of science and technology that's based on that idea of computation. And so today, I want to tell you a little bit about what that's led to. There's a lot to talk about, so I'm going to go quickly. And sometimes I'm going to summarize in a sentence what I've written a whole book about. But you know, I last gave a TED talk 13 years ago, in February 2010, soon after WolframAlpha launched, and I ended that talk with a question. Question was, is computation ultimately what's underneath everything in our universe? I gave myself a decade to find out. And actually, it could have needed a century. But in April 2020, just after the decade mark, we were thrilled to be able to announce what seems to be the ultimate machine code of the universe. And yes, it's computational. So computation isn't just a possible formalization, it's the ultimate one for our universe. It all starts from the idea that space, like matter, is made of discrete elements, and from that structure of space and everything in it, it's defined just by a network of relations between these elements that we might call atoms of space. So it's all very elegant, but deeply abstract. But here's kind of a humanized representation, a version of the very beginning of the universe. And what we're seeing here is the emergence of space and everything in it by the successive application of very simple computational rules. And remember, these dots are not atoms in any existing space. They're atoms of space that get put together to make space. And yes, if we kept going long enough, we could build our whole universe this way. So eons later, here's a chunk of space with two little black holes that, if we wait a little while, will eventually merge, generating little ripples of gravitational radiation. And remember, all of this is built from pure computation. But like fluid mechanics emerging from molecules, what emerges here is space-time and Einstein's equations for gravity, though there are deviations that we just might be able to detect, like that the dimensionality of space won't always be precisely three. And there's something else. Our computational rules can inevitably be applied in many ways, each defining a different kind of thread of time, a different path of history that can branch and merge. But as observers embedded in this universe, we're branching and merging, too. And it turns out that quantum mechanics emerges as the story of how branching minds perceive a branching universe. So the little pink lines you might be able to see here show the structure of what we call branchial space, the space of quantum branches. And one of the stunningly beautiful things, at least for physicists like me, is that the same phenomenon that in physical space gives us gravity, in branchial space gives us quantum mechanics. So in the history of science so far, I think we can identify sort of four broad paradigms for making models of the world that can be distinguished kind of by how they deal with time. So in antiquity and in plenty of areas of science, even today, it's all about kind of, what are things made of. And time doesn't really enter. But in the 1600s came the idea of modeling things with mathematical formulas in which time enters, but basically just as a coordinate value. Then in the 1980s, and this is something in which I was deeply involved, came the idea of making models by starting with simple computational rules and just letting them run. So can one predict what will happen? No. There's what I call computational irreducibility, in which, in effect, the passage of time corresponds to an irreducible computation that we have to run in order to work out how it will turn out. But now there's kind of something, something even more -- in our physics project, there’s things that have become multi-computational, with many threads of time that can only be knitted together by an observer. So it's kind of a new paradigm that actually seems to unlock things not only in fundamental physics, but also in the foundations of mathematics and computer science, and possibly in areas like biology and economics as well. So I talked about building up the universe by repeatedly applying a computational rule. But how is that rule picked? Well, actually it isn't, because all possible rules are used, and we're building up what I call the ruliad, the kind of deeply abstract but unique object that is the entangled limit of all possible computational processes. Here's a tiny fragment of it shown in terms of Turing machines. So this ruliad is everything. And we as observers are necessarily part of it. In the ruliad as a whole, in a sense, everything computationally possible can happen. But observers like us just sample specific slices of the ruliad. And there are two crucial facts about us. First, we're computationally bounded, our minds are limited, and second, we believe we're persistent in time, even though we're made of different atoms of space at every moment. So then, here's the big result. What observers with those characteristics perceive in the ruliad necessarily follows certain laws. And those laws turn out to be precisely the three key theories of 20th century physics: general relativity, quantum mechanics, and statistical mechanics in the second law. So it's because we're observers like us that we perceive the laws of physics we do. We can think of sort of different minds as being at different places in rulial space. Human minds who think alike are nearby, animals further away, and further out, we get to kind of alien minds where it's hard to make a translation. So how can we get intuition for all of this? Well, one thing we can do is use generative AI to take what amounts to an incredibly tiny slice of the ruliad aligned with images we humans have produced. We can think of this as sort of a place in the ruliad described by using the concept of a cat in a party hat. So zooming out, we saw there what we might call Cat Island. Pretty soon we’re in a kind of an inter-concept space. Occasionally things will look familiar, but mostly, what we'll see is things we humans don't have words for. In physical space, we explore the universe by sending out spacecraft. In rulial space, we explore more by expanding our concepts and our paradigms. We can kind of get a sense of what's out there by sampling possible rules, doing what I call ruliology. So even with incredibly simple rules, there's incredible richness. But the issue is that most of it doesn't yet connect with things we humans understand or care about. It's like when we look at the natural world and only gradually realize that we can use features of it for technology. So even after everything our civilization has achieved, we're just at the very, very beginning of exploring rulial space. What about AIs? Well, just like we can do ruliology, AIs can in principle go out and explore rulial space. Left to their own devices, though, they'll mostly just be doing things we humans don't connect with or care about. So the big achievements of AI in recent times have been about making systems that are closely aligned with us humans. We train LLMs on billions of web pages so they can produce texts that's typical of what we humans write. And yes, the fact that this works is undoubtedly telling us some deep scientific things about the semantic grammar of language and generalizations of things like logic that perhaps we should have known centuries ago. You know, for much of human history, we were kind of like the LLMs, figuring things out by kind of matching patterns in our minds. But then came more systematic formalization and eventually computation. And with that, we got a whole other level of power to truly create new things and to, in effect, go wherever we want in the ruliad. But the challenge is to do that in a way that connects with what we humans, and our AIs, understand. In fact, I've devoted a large part of my life to kind of trying to build that bridge. It's all been about creating a language for expressing ourselves computationally, a language for computational thinking. The goal is to formalize what we know about the world in computational terms, to have computational ways to represent cities and chemicals and movies and humor and formulas and our knowledge about them. It’s been a vast undertaking that spanned more than four decades of my life, but it's something very unique and different. But I'm happy to report that in what has been Mathematica and is now the Wolfram Language, I think we firmly succeeded in creating a truly full-scale computational language. In effect, every one of these functions here can be thought of as formalizing and encapsulating, in computational terms, some facet of the intellectual achievements of our civilization. It's sort of the most concentrated form of intellectual expression that I know, sort of finding the essence of everything and coherently expressing it in the design of our computational language. For me personally, it's been an amazing journey, kind of, year after year, building the sort of tower of ideas and technology that's needed. And nowadays sharing that process with the world in things like open live streams and so on. A few centuries ago, the development of mathematical notation, and what amounts to the language of mathematics, gave a systematic way to express math and made possible algebra and calculus, and eventually all of modern mathematical science. And computational language now provides a similar path, letting us ultimately create a computational X for all imaginable fields X. I mean, we've seen the growth of computer science, CS, but computational language opens up something ultimately much bigger and broader, CX. I mean, for 70 years we've had programming languages which are about telling computers in their terms what to do. But computational language is about something intellectually much bigger. It's about taking everything we can think about and operationalizing it in computational terms. You know, I built the Wolfram Language first and foremost because I wanted to use it myself. And now when I use it, I feel like it's kind of giving me some kind of superpower. I just have to imagine something in computational terms. And then the language sort of almost magically lets me bring it into reality, see its consequences, and build on them. And yes, that's the sort of superpower that's let me do things like our physics project. And over the past 35 years, it's been my great privilege to share this superpower with many other people, and by doing so, to have enabled an incredible number of advances across many fields. It's sort of a wonderful thing to see people, researchers, CEOs, kids, using our language to fluently think in computational terms, kind of crispening up their own thinking, and then in effect, automatically calling in computational superpowers. And now it's not just people who can do that. AIs can use our computational language as a tool, too. Yes, to get their facts straight, but even more importantly, to compute new facts. There are already some integrations of our technology into LLMs. There's a lot more you'll be seeing soon. And, you know, when it comes to building new things in a very powerful emerging workflow, it's basically to start by telling the LLM roughly what you want, then to have it try to express that in precise Wolfram Language, then, and this is a critical feature of our computational language, compared to, for example, programming language, you as a human can read the code, and if it does what you want, you can use it as kind of a dependable component to build on. OK, but let's say we use more and more AI, more and more computation. What's the world going to be like? From the industrial revolution on, we’ve been used to doing engineering where we can in effect, see how the gears mesh to understand how things work. But computational irreducibility now shows us that that won't always be possible. We won't always be able to make a kind of simple human or, say, mathematical narrative to explain or predict what a system will do. And yes, this is science, in effect, eating itself from the inside. From all the successes of mathematical science, we've come to believe that somehow, if we only could find them, there'd be formulas to kind of predict everything. But now computational irreducibility shows us that that isn't true. And that in effect, to find out what a system will do, we have to go through the same irreducible computational steps as the system itself. Yes, it's a weakness of science, but it's also why the passage of time is significant and meaningful and why we can't just sort of jump ahead to get the answer. We have to live the steps. It's actually going to be, I think, a great societal dilemma of the future. If we let our AIs achieve their kind of full computational potential, they'll have lots of computational irreducibility and we won't be able to predict what they'll do. But if we put constraints on them to make them more predictable, we'll limit what they can do for us. So what will it feel like if our world is full of computational irreducibility? Well, it's really nothing new because that's the story with much of nature. And what's happened there is that we've found ways to operate within nature, even though nature can sometimes still surprise us. And so it will be with the AIs. We might give them a constitution, but there will always be consequences we can't predict. Of course, even figuring out societally what we want from the AIs is hard. Maybe we need you know, a promptocracy where people write prompts instead of just voting. But basically, every control the outcome scheme seems full of both political philosophy and computational irreducibility gotchas. You know, if we look at the whole arc of human history, the one thing that's systematically changed is that more and more gets automated. And LLMs just gave us a dramatic and unexpected example of that. So what does that mean? Does that mean that in the end, us humans will have nothing to do? Well, if we look at history, what seems to happen is that when one thing gets automated away, it opens up lots of new things to do. And as economies develop, the pie chart of occupations seems to get more and more fragmented. And now we're back to the ruliad. Because at a foundational level, what's happening is that automation is opening up more directions to go in the ruliad. But there's no abstract way to choose between these. It's a question of what we humans want, and it requires kind of humans doing work to define that. So a society of AI as sort of untethered by human input, would effectively go off and explore the whole ruliad. But most of what they do would seem to us random and pointless, much like most of nature doesn't seem to us right now, like it's achieving a purpose. I mean, one used to imagine that to build things that are useful to us, we'd have to do it kind of step by step. But AI and the whole phenomenon of computation tell us that really what we need is more just to define what we want. Then computation, AI, automation can make it happen. And yes, I think the key to defining in a clear way what we want is computational language. And, you know, even after 35 years, for many people, Wolfram Language is still sort of an artifact from the future. If your job is to program, it seems like a cheat. How come you can do in an hour what would usually take you a week? But it can also be kind of daunting because having dashed off that one thing, you now have to conceptualize the next thing. Of course, it's great for CEOs and CTOs and intellectual leaders who are ready to race on to the next thing. And indeed, it's an impressively popular thing in that set. In a sense, what's happening is that Wolfram Language shifts from concentrating on mechanics to concentrating on conceptualization, and the key to that conceptualization is broad computational thinking. So how can one learn to do that? It's not really a story of CS, it's really a story of CX. And as a kind of education, it's more like liberal arts than STEM. It's part of a trend that when you automate technical execution, what becomes important is not figuring out how to do things, but what to do. And that's more a story of broad knowledge and general thinking than any kind of narrow specialization. You know, there's sort of an unexpected human centeredness to all of this. We might have thought that with the advance of science and technology, the particulars of us humans would become ever less relevant. But we've discovered that that's not true, and that, in fact, everything, even our physics, depends on how we humans happen to have sampled the ruliad. Before our physics project, we didn't know if our universe really was computational, but now it's pretty clear that it is. And from that, we're sort of inexorably led to the ruliad, with all its kind of vastness so hugely greater than the physical space in our universe. So where will we go in the ruliad? Computational language is what lets us chart our path. It lets us humans define our goals and our journeys. And what's amazing is that all the power and depth of what's out there in the ruliad is accessible to everyone. One just has to learn to harness those computational superpowers, which kind of starts here, you know, our portal to the ruliad. Thank you. (Applause)