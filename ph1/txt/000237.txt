Brian S. Lowery: If you could produce a more immersive social experience, now everybody's having their individual social experiences. Like now what I worry about with AI, with VR, with all these kind of technologies that are expanding, we all inhabit our own singular world. That is more frightening to me than like, you know, that we all converged in the same experience. [Intersections] [Brian S. Lowery: Social psychologist] [Kylan Gibbs: Technologist] BSL: So what makes a human a human? (Laughter) Kylan Gibbs: It’s one of those questions, isn’t it? I mean, there's like, two ways I would look at it. One is from my personal life and one is from my work life. One thing that's interesting is like, there's been points when I've been spending four to five hours a day interacting with AI. And the interesting thing that happens in that is the things that you notice, when you first start interacting with it, oh, this is really realistic. Similarly when people first had black and white TV and they're like, wow, this is like real life. But then as you get used to it, you start to kind of realize, the things that make it less authentic. And I think something that I realized with AI is there's certain ways that we interact that are just more spontaneous. There's something about the predictability of AI that teaches you about the spontaneity of being human. The ways they communicate, the naturalness, the contextual awareness. These little things that all add up. That's on the technical side. On the other side, there's something of just the shared experience of being human that actually I think differentiates it from other animals’ experience. You know, you have a traumatic moment in your life, and then you start to resonate with other people's. I feel like every time I've had something nearly catastrophic, it opened up a new door of empathy, and then you start to be like, oh man, that really hurt, you know? Or like when you cry about something, you're like, wow. And then you start to remember, like this is what usually happens to me. I start crying about something, and then I think about all the things that I did for my mom or my grandma and the things that they felt. And I feel like there's something in that kind of like shared experience where we have these things that differentiate us, we’re all different people. But there’s something about those common feelings that it all kind of arises from that. Anyway, that's one thought. BSL: I love that answer, and I want to say that you're not normal in that way. Here's why I don't think you're normal. People anthropomorphize anything. It doesn't have to even be that good, right? It doesn't have to be anywhere near as good AI for people to treat it like it has some human character, people treat their cars like they're people. So I'm surprised that when you interact with it a lot, it feels less real to you. KG: There's something about resolution. It's like the way of seeing the world and you kind of increase this. It's like the same reason you can't look at TV that's not 4K now. And it's someone I think who worked on early VR was saying, you know, the interesting thing about it was when you stepped out of it, you're like, oh, the real world is actually amazing. And it's actually really hard to recreate that in technology. And I think the same is true for AI, it's like maybe for some people, when they interact with it, the thing that they see is some commonality. But the thing that I always notice is, this is very different from the conversations I have with my parents. Even when it says something similar, there’s something off. It's those little things, that's like I think what, over time, will add up as people use AI more, is they’ll start to recognize, and I can't even point at them like, what are those nuances, though, that make us human? BSL: You just know it when you see it and you're like, and it's missing an AI. I mean that's also interesting because what you just suggested is that the more people use AI, the less real it's going to feel to people. Do you think that's what's going to happen? KG: I mean, there's probably another case, you know, it's the same way as, you know, your Instagram and Facebook feed isn't a real conversation. There are certainly, kids especially, who would look at those kinds of feeds and feel like, oh, that's a real representation of my friends or my favorite celebrities or whatever I actually think, when it's like completely -- I shouldn't say completely -- largely false. And I do think something similar will happen with AI, where some people for sure will almost be encaptured. And they will believe that that's the most realistic thing that exists and then start to compare people to that. But I think that, you know, if you have that degree of empathy, you'll be like, oh, there's something off here. It's the same way even if you use a Zoom call, there's something off. It's hard to pick it up. But like, I’m not picking up all the signals, and it's the very little nuances that you probably just subtly pick up as well. BSL: So you don't think that the technology is going to advance quickly enough, where it’ll overcome those little things fast enough to capture all of us? You're not worried about that? KG: I am definitely worried about that. Mainly because because I think for most people it's easy, right? So the thing about AI is it's so beholden, at least if you think about like, the chatbot styles, it's so beholden to what we want. And that's kind of like what people, I think, a lot of people want in their life or they need, is the sense of control. And the AI gives you the sense that, like, I can control this anthropomorphic thing. And honestly, one of my fears is that people get used to that. And what does it mean when I get used to interacting with something that is beholden to only my views and interests, and then I go and interact with a human who has their own interests? BSL: Do you think people want control? I think people want to be controlled. KG: Maybe it's a form of control, though. To be controlled is a predictability, I guess. BSL: Yeah, people want the world to make sense, don't you think? KG: Yes, yes, I think they also want the world to be ... There's something about, like, preferring predictability over optimality. So, like, I've even felt it when you have, you know, a mental health moment, you have friends who have mental health moments. The things that I've always seen as interesting is your brain and your mind prefer to stay in a state that's familiar, even if it's worse. So if you're in like a depressed state, you almost would rather like stick in that than break outside of it, right? So there's something about things that are familiar rather than actually better. And I don't know, there's a bias towards, you know, you almost identifying then with those kinds of states. BSL: Yeah, there's research on this. One, it's called the status quo bias. People like things that are already there. And two, people like to have what they believe about themselves affirmed if they really believe them, even if they're not positive. So that is true. So, like, what does that look like in AI? (Laughter) KG: I mean, it's definitely interesting to me that people seem to love like, you talk to a lot of these things and they sound like computers and they sound like AI, but people love it because it's kind of familiar, it's controllable. If you start to add lots of personalities and these kinds of things, it makes sense in context, but I found it interesting that as we started developing these AI systems that people interact with, they all have this kind of similar voice. And it's a very "AI voice." You can kind of tell that you're talking to an AI. Maybe that’s intentional. But there is something there, where like, I think people have a preference to getting what they want from humans, from humans, and from AI, from AI. But that could blend, there's already lots of, you know, people in certain demographics who spend a lot of time on the internet and they start to identify, that's their favorite form of interacting with people. And so I do think that there's a reality where, as we move into the future, there will be people who bias towards that for whatever reasons. Whether it's the comfort of knowing that someone's not judging them, whether it's like the format that it speaks to you with, that will kind of bias towards preferring those types of interactions. But on the other hand, I always think there’ll be a distribution of people, and you'll have some people who really don't like it. And, you know, like I was saying, the more that I interact with it now, I find it almost painful because I just pick up on so many of these issues that you're like, I can't even use it at a certain point. And, you know, you'd think that, like, you know, I’m in the AI space, and I write 20-page docs. I don't need AI for a single bit of it because it does remove that voice. And I do also wonder, though, as people interact with it more, will they either identify the differences or start to conform to the things that they're trained with AI. It's the same as if you interact with your partner for example, right? You start to be biased by the communication because you're talking so much. BSL: You mean they're training you? KG: They're training you. Your partner is probably like, you know, they have a preferred way of communicating. You get used to it, these kinds of things. So I do wonder if, as people interact with AI more, that they'll kind of all converge. That's probably one of my biggest fears actually of AI. BSL: I'm concerned about the exact opposite. I'm going to shift a little bit. So when we talk about AI, what you're describing, it's usually like dyadic interactions. Like, I'm interacting with one AI, one agent. But really what people do is interact with multiple people, right? You interact in some community or some small group setting. And I'm surprised that there's not more of that in AI. So you're also in gaming. I don't really game, but my understanding is that a lot of the gaming is about connecting with the people, and it's a community kind of experience. So there's two things. One, I'm really surprised that AI seems so focused on these, like, one-on-one interactions as opposed to like, multiple AI agents creating a more immersive social experience. KG: I love you brought it up because that's really what we do. BSL: Good, so that's one. Other thing, like, the reason I worry less about convergence and more about divergence is if you could produce a more immersive social experience, now everybody’s having their individual social experiences. Like now, what I worry about with AI, with VR, with all these kind of technologies that are expanding, what we can control about our social environment, about our physical perceptions in the environment, is that we all inhabit our own singular world. That is more frightening to me than like, you know, that we all converged in the same experience. KG: Well, my mom’s a grade-seven teacher, and the one thing that she said is really interesting is if you went back like 20 years, everybody was watching the same TV shows, and they come to class and they'd all be talking about it. And now everybody watches their own favorite YouTube channel. And it's the siloing of reality. Like, what we do is when we work with games, for example, one of the interesting things is like, as people play through games, it's basically the same thing. You could have a million people go through a game, and it’s some differences but you're largely going to hit the same points. And so one of the things that we think about is, what does that mean for agency? The way we interact with media changes the way that we feel agency in the world. So if we see inert media that we can't change, it also gives you this sense that you can't change the world. And so to your point, one of the things that we want to do with games is, how do you make it so that each person can actually influence that outcome? And as you add more agents into that, that you see, OK, I interact with this one and it has a cascade effect. I love it. I mean, even in some of the stuff we've done here, the magic actually happens when you do have those agents interacting, because then you’re also not just seeing like that one-to-one interaction but the emergent effect of basically that interaction. And another thing is, if your main controls that you have in the computer is like point-and-click or, in games, jump and shoot, we're trying to see like, what does it mean if social skills like interaction like this, are the ways that you actually interact with the games, the technology and the agents. That’s a very different way of conversing or of dialogue than button presses. And I think that changes the way that you sense agents in the world. Because I think the way that most people change the world is by speaking and interacting and interacting with other humans, not by pressing buttons. I mean, arguably it's the case in some. BSL: You know, the other thing that's interesting to me is I don't think people have an understanding of the systems they exist in, right? People think about themselves as existing in like individual relationships, and they have a harder time understanding system affects like I affect you, which affects your partner, which affects  your partner's parents, right? That is a harder thing to grasp. But I think there's something that's fundamentally human about that. Like you are also impacted by all these different things going on, like, we had the person come and put on our makeup, and now I'm looking beautiful and it's affecting everybody else around me. (Laughter) KG: It's glowing. BSL: Exactly. How does that fit in? I just haven't heard people talk about it in that way, which is surprising to me, because that, I think, is what fundamentally makes humans human. It's interaction and complex social situations. KG: And these like, nested systems. And like, they all affect each other, right? You think that your small activity doesn't affect whatever higher-level political stuff, but it's all aggregate. And it's all interlinking as well. I mean, it's like the AI thing is interesting too, because I often hear people talk about it as like this evolution. You have like, you know, singular cells to monkeys to humans to AI. Whereas like, you could flip it, where it's like more like, you know, cells to organs to human to AI. It's a system overarching that just because it's trained on us and we do these things, that we actually influence that system, now that people are interacting with it, it has this interplay. And that's interesting too, when it becomes like, you know, AI isn't this singular entity. It is more of an institution or a system almost that is kind of overarching everything else. BSL: And it's also weird because it's like our vision of who we are. So when we talk about AGI, it's like we don't even know what intelligence is and we think we're going to produce something that has it. It's just an interesting situation where we talk about it, as you said, it's natural evolution, but in fact we’re creating it, and it's not clear that we know exactly what it is we're creating. KG: I actually think that one of the most interesting things is that we're starting to work on AI at a point where, like, I still think we're figuring out, you know, ourselves. Neuroscience is very early on in its days, and yet we're creating things that are like, based on our own intelligence, and we don't really understand even what's going on inside. And so to your point on, what are the effects? We don't really know yet. Every year a new paper comes out and changes how people think about child rearing. Like how to bring up a child well, like all those kinds of things. And now we're creating systems that will, you know, kind of be overarching other humans. What does that mean, I don't know. I do actually think, I happen to be in AI, we happen to be at this point in time. But if we could pause for a second, I think it would be good, another few centuries of figuring out what we are and understanding that a little bit better before we created something that was in our image. Because, we’re kind of just, you know, it's kind of like taking a photograph and like painting it, right? You're not actually getting the person and painting it. There's something about the life that's missing there. So I do agree. I think that we're honestly kind of premature, but I think it's just how, I guess, you know, life goes that things come out when they naturally should. BSL: So, I mean, you work in AI, so what's the most exciting thing for you in AI? What's your hope for it? KG: I think it's kind of back to that agency question. So I mean, you know, you read a news story, you read a book, you watch a movie, you watch a TV show, this is specific to, like, my domain, like there's something about the communication that we're having right now where, like, I'm adapting to the things that you say, to your body language, all those kinds of things, right? To, like, the people in the room we have here, all these things. And so when you have ... AI able to, sort of, help that adaptation so that you have that agency in the things that you interact with. I don't necessarily believe in fully personalized media because I think we need like a shared social context. The reason we watch a movie or a TV show is because then we can all talk about it, right? But there is something about the fact that we're all interacting with these internet objects. And so the way that technology feels, you're on a screen, it doesn't change. You're in a movie, it doesn't change. You're watching Netflix, it doesn't change depending on what you do. And I think that changes the way we see our own agency in the world. And so I hope with AI that one of the things that it does is kind of opens this door to agency in the way that we interact with media and technology in general, such that we do notice that effect that you have on systems. Because even if it's small, right, where I take a certain action and it completely changes an app or it changes an experience, maybe that helps us learn that we have an effect in the social systems as well that we're affecting. So something to that effect. BSL: So you want to make our agency more transparent. And do you think it does that, because right now I'm not sure it doesn't obfuscate our agency. KG: No I don't necessarily know. I agree, I mean this is why I think also media and games is, you know, the domain I mainly focus on. And I think it's interesting, especially because young people use it a lot. And so I've heard very veteran game developers say how people interact with games kind of trains kids how they should interact with the world. So even people who tend to be professional players in different games have different psychological profiles because they bias towards certain ways of interacting and seeing the world. The same way, I guess, if you trained in something academic, right, you have a different way of viewing it. And so if we make games and media in a way that you feel that sort of social impact as well, maybe, maybe it opens the door to like, another realm of understanding. But, yeah, I agree that like a lot of the systems that we have today give you maybe a false sense also of agency where like we were talking about the AI systems, where you actually feel like you're controlling this thing, whereas maybe it's also biasing, you know, and "controlling," having some influence over you as well. BSL: So where do you think things are going? So there's obviously a huge race among some very, very well-resourced organizations over AI, right? You know, Microsoft, Google, I mean, are the biggest maybe. And they are very quickly going to need to monetize it because this is what those companies are designed to do. Like what do you foresee? Because I just look at social media as an example. I think, at the time when it first came out, people were really excited, as a new way to connect with people and a way to stay connected to people you know, you couldn't otherwise; catch up with people you lost contact with, that sort of thing. And it changed into something else. In large part because of the way it was monetized, like going to ads, focus on attention. What's the trajectory of AI? KG: You know, I'm taking guesses. BSL: Yeah, of course, we're all taking guesses, I won’t hold you to it, don’t worry. KG: I think that the reality is, we were kind of mentioning before about the challenges of scale. And when you invest tens of billions of dollars in something, you need scale. And I think that's one of -- the way that AI is developed and specifically even the types of models we're using, the economic model of it, which is effectively the more compute you have, the better models you can create. The better models you can create, the more usage you get. The more usage you get, the better. So it has somewhat of a, honestly, like monopolistic tendency, I think, in the way that actually even like the architectures and the economy of it works. And so I think it's almost inevitable that whatever AI systems are produced by these large organizations will be pushed to scale as quickly as possible. And there's some pluses in that where like, you know, sure, they're building in feedback loops, people can give their input, it biases it. But also at the same time, what does it mean when a single model is fit to a billion people, right? So that's kind of what I meant about the converging effect where, what happens when we are pushed to produce something that fits to a billion people? There's a lot of diversity in there. And so, you know, we create these scaled systems that are fitting with the whole, like, trying to fit the whole planet. Does that work? And so I think what will, you know, we're going to go through this phase where like, yeah, you're going to have a billion people interacting the same AI. And I don't know what the effect of that will be. Even the monetization models now are kind of you pay to use these kinds of things, which are maybe OK, but certainly ads will probably enter the equation. Also, what happens when you want attention and AI is much better at that than the algorithms you even have on YouTube and Instagram. And you can start to capture that attention. And so I certainly think it's going to be an interesting little bit here now, as we see these huge organizations spending tens of billions of dollars and the choices that they make to then monetize that, and what that means for how AI proliferates. I know a lot of the folks in the organizations, and their interests have never been in that domain. But at the same time, you're beholden, you know, to stock market interests and whatever it is, then what happens? It shifts it, right? We're in a capitalist world. And that's kind of like, you know, what ultimately will change the incentives. So yeah it's interesting. I mean I am interested in, coming from your background, you have a very different stance on it. But, you know, it's all this AI stuff is interesting. But, you know, when you think, almost to your first question, what makes us human and like as people, just technology in general and specifically with AI, like where can people find the meaning in their life, the values that they find true? And how will that change, do you think, I guess, with like the advent of these new technologies? Or how have you seen it change with the technologies we've already seen come to life? BSL: This is going to sound like a funny answer. I think people are too worked up about technology, personally. I mean, you know, we had this conversation. I think, you know, people have been using technology since we've been human. So paper was a huge invention. Talked about this. The printing press, huge invention. Computer, huge invention. Internet, huge invention. AI, great, another huge invention. And through all of that, I think what you see in a lot of the biggest technologies is the desire to connect with other human beings. I think what fundamentally makes us human is our connection to other human beings, our ability to engage with other human beings, and like consciousness and all these other things I think are necessary preconditions. But really, what makes us human is connections with other humans. And that is incredibly complex. And I don't think we're close in terms of technology of replicating that. I mean, even what you described it's like you have this feeling of like, this isn't right, this is off. And even if you felt like it was right, it still would be off in ways you didn't quite get. I don't think we're close. Though because it's designed to pull our attention away from other things, I think it impedes our ability to do what we all kind of want to do, which is interact with each other. And it might change the way we interact with each other in a way that might feel less fulfilling. And I think you see some of that in social interactions now. Some of that I mean, recently maybe, COVID was an issue. But, you know, people feeling less comfortable in face-to-face interactions. Like people dating, there's no serendipity in hanging out and you meet who you meet. It's like you're using an algorithm to try to present to you options. That's a very different world. So even that's prior to AI. And I don't know how AI is going to further influence that. KG: And I guess just even like the general point, how core do you think the need for connection is in the sense that, you know, I've heard some parents say that, through COVID, their kids went through a major change, you know, these regressions, their different habits and these kinds of things because they weren't connecting with people. And then it's taken years to overcome that. So I do also wonder, like, you know, whether it's through technology or things like COVID or just like circumstances, could we lose that need for connection? Or even if we need it, you know, we might lose the desire for it and feel emotional trauma as a result, but still not go for it. Like, how core do you think it is? And do you think we're safe in that kind of need? BSL: So I'm going to give you the most extreme answer, which is I think the true one. That you will cease to be human if you don't have a need for human connection. Like I think you will be a physical person, but you will literally break down as a human being. And this is why in part -- Social isolation or solitary confinement is considered inhumane. Because people literally break down, you will start to have hallucinations. You will break down mentally and physically absent human connection. So I don’t think there’s any possibility, in my mind, of losing the need. Like, you may get less than you need, and that will have negative consequences for you. But I'm not worried about people not wanting to be around people. KG: Are you worried that, like, things like social media or AI or any of these things could give you that sense that you're fulfilling that need, but not actually fulfilling it? It's totally true, right? Solitary confinement is a great example because we need it. We absolutely lose our sanity as well as, you know, our well-being. But maybe we can, you know, technology can manufacture the sense that we're fulfilling it. And then over time, we see these mental health crises evolve as a result? BSL: Yeah, that's a good question. I think it's unlikely, but I don't know. Honestly I don't know. I'll talk about meaning for a second. And I think of that as fundamentally tied to our need for connection to other people. I think sometimes we confuse, for example, our need for meaning, with a desire for personal achievement. That we chase personal achievement and what we're trying to do is generate meaning. So I think we can be confused and we can have those needs displaced into less productive routes. But I don't think it's going away. But, you know, I don't know that it's the healthiest. KG: No, I'm totally aligned. Thank you, Brian, that was an awesome conversation.  BSL: It was great to talk to you. Really fantastic and  super informative. Thank you.